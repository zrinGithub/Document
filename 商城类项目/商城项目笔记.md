# 商城项目笔记

[TOC]



## 1 项目搭建

### 1.1 虚拟机

软件使用`VMware® Workstation 15 Pro`，版本`15.5.1 build-15018445`

镜像使用`CentOS-7-x86_64-Minimal-1908.iso`（docker安装需要）

因为之前的笔记比较散，所以这里尽量做最全面的部署说明：



#### 1.1.1 安装

这个镜像就是最小镜像，所以没有图形化界面：

进入界面，选择`Install CentOs7`之后随便选。

设定root密码123456



##### 1.1.1.1 上传下载文件

`yum -y install lrzsz `

#### 1.1.2 网络配置

##### 1.1.2.1 网关与ip

首先需要查看当前虚拟机网关的地址，具体位置：

`控制面板\网络和 Internet\网络连接`

查看VMnet8的网关地址



也可以直接在管理员模式下启动Vmware，然后点击菜单->编辑->虚拟网络编辑器里面查看

```shell
编辑
vim /etc/sysconfig/network-scripts/ifcfg-ens33 

内容
......
BOOTPROTO=static
NAME=ens33
DEVICE=ens33
ONBOOT=yes
IPADDR=192.168.190.200
NETMASK=255.255.255.0
GATEWAY=这里就是网关地址
DNS1=8.8.8.8

重启
service network restart
```



如果是复制的机器，建议在开启的时候直接选择移动的机器，然后修改ip地址即可，如果选择复制，可能需要设计网卡的修改。



##### 1.1.2.2 关闭防火墙

因为后面需要开放端口，这里我们直接关闭防火墙

```shell
#查看防火墙状态
firewall-cmd --state

#停止firewall
systemctl stop firewalld.service

#禁止firewall开机自启
systemctl disable firewalld.service
```



#### 1.1.3 Docker安装

参考官网：https://docs.docker.com/install/linux/docker-ce/centos/

安装需要CentOs7主版本

docker包含 EE企业版本和CE社区版本。



官网关于stable/nightly/test三个更新渠道的说明

> - **Stable** gives you latest releases for general availability.
> - **Test** gives pre-releases that are ready for testing before general availability.
> - **Nightly** gives you latest builds of work in progress for the next major release.





##### 1.1.3.1 使用Docker Repository来安装

官网推荐设置Docker repository来安装：



- 删除旧版本

```shell
$ sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```



- 安装`yum-utils`包（提供`yum-config-manager`功能）并设定稳定的仓库

```shell
$ sudo yum install -y yum-utils

$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
```



- 官方建议安装nightly或者test更新渠道

```shell
开启nightly repository
$ sudo yum-config-manager --enable docker-ce-nightly

启动test
$ sudo yum-config-manager --enable docker-ce-test

关闭nightly或者test使用--disable即可
$ sudo yum-config-manager --disable docker-ce-nightly
```



- 安装特定版本

```shell
查看版本列表
$ sudo yum list docker-ce --showduplicates | sort -r

docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable
docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable
docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable
docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable

安装时候使用docker-ce加上版本号，如docker-ce-18.06.0.ce('-'前面为版本号)
$ sudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io
```



- 安装最新版本

```shell
$ sudo yum install docker-ce docker-ce-cli containerd.io
```



- 启动

```shell
$ sudo systemctl start docker
```



- 测试

```shell
$ sudo docker run hello-world
```



##### 1.1.3.2 使用安装包

- 下载版本 https://download.docker.com/linux/centos/7/x86_64/ 选择安装版本
- 安装：`yum install /path/to/package.rpm`
- 启动：`systemctl start docker`
- 测试：`docker run hello-world`



##### 1.1.3.3 使用阿里docker社区版yum源安装

```shell
 # 安装wget
 yum install wget
 
 # 下载阿里云docker社区版yum源
 cd /etc/yum.repos.d/
 wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
 
 # 查看docker安装包
 yum list | grep docker
 
 # 安装docker ce社区版本
 yum install -y docker-ce.x86_64
 
 # 设置开机启动
 systemctl enable docker
 
 # 更新xfsprogs
 yum -y update xfsprogs
 
 # 启动docker
 systemctl start docker

 # 查看版本
 docker version
 
 # 查看详细信息
 docker info
```



#### 1.1.4 设置Docker容器自动启动

```shell
docker update --restart=always CONTAINER_NAME/CONTAINER_ID
```



#### 1.1.5 docker安装mysql

```shell
# 查看可用版本
docker search mysql

# 拉取官方镜像
docker pull mysql:5.7

#运行，-p前面是宿主机地址，后面是容器地址
docker run -itd --name z-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7

#设定开机自启
docker update --restart=always z-mysql

#进入容器
docker exec -it z-mysql /bin/bash
```





#### 1.1.6 docker安装redis

https://hub.docker.com/_/redis/



因为涉及远程连接，需要挂载外部文件

```shell
mkdir -p /root/docker/redis/conf

#这里我直接找官网http://download.redis.io/releases/的redis.conf文件到/root/docker/redis/conf目录下
#这里配置密码，可以吧protected-mode打开
vim /root/docker/redis/conf/redis.conf
#取消访问地址限制
#bind 127.0.0.1 
#设置访问密码，redis需要认证使用命令： auth myPassword
#或者在连接的时候./redis-cli -h 192.168.190.200 -p 6379 -a 123456
protected-mode no
requirepass 123456  
```



镜像：

```shell
# 查看可用版本
docker search redis

# 拉取官方镜像
docker pull redis

#运行，-p前面是宿主机地址，后面是容器地址
docker run -itd --name z-redis -p 6379:6379 \
-v /root/docker/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
redis redis-server /usr/local/etc/redis/redis.conf

#设定开机自启
docker update --restart=always z-redis

#进入容器
docker exec -it z-redis /bin/bash
```



#### 1.5.7 docker镜像打包和导入

有的时候我们需要使用自己的镜像：

```shell
#保存压缩镜像到本地
docker save IMAGE_ID | gzip > xxx.tar.gz
#发送到安装机器
scp xxx.tar.gz root@192.168.190.200:/root
#解压并加载到本地仓库
gunzip -c xxx.tar.gz | docker load
#重命名
docker tag IMAGE_ID xxx
```



#### 1.5.8 docker关闭全部服务

`docker stop $(docker ps -a -q)`





### 1.3 基础代码结构

#### 1.3.1 父工程

父工程主要负责导入springboot、springcloud



> parent标签主要用于实现复用父类的依赖以及统一管理依赖的版本号。





### 1.4 服务地址与端口

#### 1.4.1 项目服务

| 服务               | 说明           | 端口 |
| ------------------ | -------------- | ---- |
| eureka-server      | eureka注册中心 | 8000 |
| fastdfs-ops        | fastdfs操作    | 8001 |
| shop-service-canal | canal          | 8002 |
| product-service    | 商品服务       | 8003 |
| search-service     | 搜索服务       | 8004 |
| http-service       | rest请求服务   | 8005 |
| gateway-web        | 系统微服务网关 | 9000 |
| user-service       | 用户服务       | 8006 |
| oauth-service      | 认证服务       | 9100 |



#### 1.4.2 服务配置

均使用一台虚拟机安装，所以地址都在`192.168.190.200`

| 服务            | 端口                | 相关配置文件                                                 |
| --------------- | ------------------- | ------------------------------------------------------------ |
| fastdfs tracker | 22122 nginx端口8080 | nginx配置文件：/etc/nginx/conf/nginx.conf<br />tracker配置文件：/etc/fdfs/tracker.conf |
| fastdfs storage | 23000 nginx端口8080 | nginx配置文件：/etc/nginx/conf/nginx.conf<br />storage配置文件：/etc/fdfs/storage.conf<br />存储位置：/data/fast_data |
| redis           | 6379                |                                                              |
| mysql           | 3306                |                                                              |
| openresty nginx | 80                  | /usr/local/openresty/nginx/                                  |
| canal           | 11111               | canal-server/conf/example/instance.properties<br/>canal-server/conf/canal.properties |
| es              | 9200                | /usr/share/elasticsearch/config/elasticsearch.yml            |
| kibana          | 5601                |                                                              |



### 1.5 Jmeter

Jmeter可以用于负载和性能测试。

官网：https://jmeter.apache.org/



#### 1.5.1 JMeter安装

本地先要有jdk环境，这里本地的jdk是1.8。



JMeter下载地址 ： https://jmeter.apache.org/download_jmeter.cgi

解压后点击bin路径下的jmeter.bat即可



### 1.6 代码生成器

#### 1.6.1 mybatis sql语句

如果想要sql语句比较详细的，可以使用https://github.com/zrinGithub/mybatisReverseWithComment



#### 1.6.2 mybatis plus 

因为项目使用的mybatis plus，所以这里使用插件来生成，可以使用shop-common-db项目里面执行：

`mvn com.baomidou:mybatisplus-maven-plugin:1.0:code`生成代码



使用前需要在pom.xml里面添加插件:

```xml
   <build>
        <plugins>
            <plugin>
                <groupId>com.baomidou</groupId>
                <artifactId>mybatisplus-maven-plugin</artifactId>
                <version>1.0</version>
                <configuration>
                    <!-- 输出目录(默认java.io.tmpdir) -->
                    <outputDir>d:/tmp/</outputDir>
                    <!-- 是否覆盖同名文件(默认false) -->
                    <fileOverride>true</fileOverride>
                    <!-- mapper.xml 中添加二级缓存配置(默认true) -->
                    <enableCache>true</enableCache>
                    <!-- 开发者名称 -->
                    <author>zhangr</author>
                    <!-- 数据源配置，( **必配** ) -->
                    <dataSource>
                        <driverName>com.mysql.jdbc.Driver</driverName>
                        <url>jdbc:mysql://localhost:3306/shop-order?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC</url>
                        <username>root</username>
                        <password>123456</password>
                    </dataSource>
                    <strategy>
                        <!-- 字段生成策略，四种类型，从名称就能看出来含义
                        nochange(默认),
                        underline_to_camel,(下划线转驼峰)
                        remove_prefix,(去除第一个下划线的前部分，后面保持不变)
                        remove_prefix_and_camel(去除第一个下划线的前部分，后面转驼峰)
                        -->
                        <naming>underline_to_camel</naming>
                        <!-- ID策略 是LONG还是STRING类型(默认stringtype)-->
                        <!--<serviceIdType>stringtype</serviceIdType>-->
                        <!--Entity中的ID生成策略（默认 id_worker）-->
                        <idGenType>uuid</idGenType>
                        <!--自定义超类-->
                        <!--<superServiceClass>net.hyman.base.BaseService</superServiceClass>-->
                        <!-- 要包含的表 与exclude 二选一配置-->
                        <include>
                            <property>shop_sub_order</property>
                        </include>
                        <!-- 要排bean除的表 -->
                        <!--<exclude>-->
                        <!--<property>order</property>-->
                        <!--</exclude>-->
                    </strategy>
                    <packageInfo>
                        <!-- 父级包名称，如果不写，下面的service等就需要写全包名(默认com.baomidou) -->
                        <parent>com.zr.order</parent>
                        <!--service包名(默认service)-->
                        <service>service</service>
                        <!--serviceImpl包名(默认service.impl)-->
                        <serviceImpl>service.impl</serviceImpl>
                        <!--entity包名(默认entity)-->
                        <entity>entity</entity>
                        <!--mapper包名(默认mapper)-->
                        <mapper>mapper</mapper>
                        <!--xml包名(默认mapper.xml)-->
                        <xml>mapper</xml>
                    </packageInfo>
                </configuration>
                <dependencies>
                    <dependency>
                        <groupId>mysql</groupId>
                        <artifactId>mysql-connector-java</artifactId>
                        <version>5.1.29</version>
                    </dependency>
                </dependencies>
            </plugin>
        </plugins>
    </build>
```



#### 1.6.3 easyCode

属于idea的一款插件（https://plugins.jetbrains.com/plugin/10954-easy-code），这个功能比较强大，但是要自己修改模板，一般我们都需要swagger注解以及lombak注解，所以用这个基本不用再改。



安装插件后，在右侧Database里面添加mysql数据库：

填写用户名密码以及URL如：

`jdbc:mysql://localhost:3306/shop-order?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC`

<img src="./images/easyCode使用-数据库连接.png" style="zoom:67%;" />

连接成功后，点开，选中表右键出现EasyCode菜单栏，可以进行数据库字段配置或者直接生成对应数据



生成的模板数据可以在菜单File->Settings->Other Settings->Easy Code里面配置



## 2 fastDfs

fastDfs是开源的轻量级分布式文件系统，包含tracker server、storage server。

tracker负责复杂均衡和调度，上传的时候寻找可用的storage来存储。

<img src="./images/fastdfs上传.png" style="zoom:67%;" />





### 2.1 Docker安装fastDfs

- 拉取镜像：

  ```shell
  docker pull morunchang/fastdfs
  
  #因为拉取太慢了，我也不知道能不能拉下来，所以从其他虚拟机拷贝的
  #保存压缩镜像到本地
  docker save a729ac95698a | gzip > fastdfs.tar.gz
  #发送到安装机器
  scp fastdfs.tar.gz root@192.168.190.200:/root
  #解压并加载到本地仓库
  gunzip -c fastdfs.tar.gz | docker load
  #重命名
  docker tag a729ac95698a morunchang/fastdfs
  ```

  

- 运行tracker：

  ```shell
  docker run -d --name tracker --net=host morunchang/fastdfs sh tracker.sh
  --net:使用的网路模式为host，也就是共享主机network namespace可以直接访问主机的网络信息，缺点是两个容器的端口必须不同，因为都是使用主机的接口。
  ```

  

- 运行storage：

  ```shell
docker run -d --name storage --net=host -e TRACKER_IP=<your tracker server address>:22122 -e GROUP_NAME=<group name> morunchang/fastdfs sh storage.sh
  
  --net:使用的网路模式为host，也就是共享主机network namespace可以直接访问主机的网络信息，缺点是两个容器的端口必须不同，因为都是使用主机的接口。
  -e添加到环境变量
  	TRACKER_IP  track机器的ip
  	GROUP_NAME	组名，也就是storage的组，新的storage服务器组名需要改变
  
  
  #本例使用
  docker run -d --name storage --net=host -e TRACKER_IP=192.168.190.200:22122 -e GROUP_NAME=group1 morunchang/fastdfs sh storage.sh
  ```
  
  
  
- storage内部修改nginx配置

  ```shell
  #进入容器
  docker exec -it storage /bin/bash
  #修改nginx配置
  vim /etc/nginx/conf/nginx.conf
  
  #里面已经有配置了，nginx端口8080
  location ~ /M00 {
  	root /data/fast_data/data;
      ngx_fastdfs_module;
  }
  #如果不希望浏览器缓存的话（比如删除希望立即删除）
  add_header Cache-Control no-store;
  
  #退出容器
  exit
  
  #重启storage容器
  docker restart storage
  ```



- 查看启动的容器：`docker ps`

- 开机启动设置：

  ```shell
  docker update --restart=always tracker
  docker update --restart=always storage
  ```

- 查看配置文件

  ```shell
  docker exec -it storage /bin/bash
  cd /etc/fdfs/
  vim storage.conf
  #里面的store_path0表示文件的位置
  store_path0=/data/fast_data
  #tracker的地址
  tracker_server=192.168.211.132:22122
  ```

  

### 2.2 fastDfs服务代码

#### 2.2.1 安装依赖

看了几个不同的项目，基本都是使用github上面的这个项目： https://github.com/happyfish100/fastdfs-client-java

文档里面写得很清楚了，使用idea的话install一下就可以了。

安装到本地库之后使用pom导入（注意版本号和安装的一样）：

```xml
        <dependency>
            <groupId>org.csource</groupId>
            <artifactId>fastdfs-client-java</artifactId>
            <version>1.29-SNAPSHOT</version>
        </dependency>
```



#### 2.2.2 配置文件

`application.yml`

```yaml
spring:
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
  application:
    name: fastdfs-ops
server:
  port: 8001
eureka:
  client:
    service-url:
      defaultZone: http://test:123456@127.0.0.1:8000/eureka/
  instance:
    prefer-ip-address: true
feign:
  hystrix:
    enabled: true
```



`fdfs_client.conf`

```properties
connect_timeout = 60
network_timeout = 60
charset = UTF-8
http.tracker_http_port = 8080
tracker_server = 192.168.190.200:22122
```



启动类：

```java
@SpringBootApplication
@EnableEurekaClient
@EnableSwagger2
public class FastDFSApplication {
    public static void main(String[] args) {
        SpringApplication.run(FastDFSApplication.class, args);
    }
}
```



#### 2.2.3 文件上传下载实现

包装类：

```java
@Data
@Accessors(chain = true)
public class FastDFSFile {
    //文件名字
    private String name;
    //文件内容
    private byte[] content;
    //文件扩展名
    private String ext;
    //文件创建作者
    private String author;
}
```



-----



Client代码：

```java
@Component
@Slf4j
public class FastDFSClient {
    private TrackerServer trackerServer;
    private TrackerClient trackerClient;
    private StorageServer storageServer;
    //使用StorageClient1而不是StorageClient只是为了方便操作组名和文件路径（想一下你不用自己去加分隔符了）
    private StorageClient1 storageClient;

    //设定默认的配置，可以在application.yml里面修改
    @Value("${fastdfs.http.permit.types:png,jpg,jpeg,doc,xls,pdf,bmp,gif}")
    private String permitTypes;
    private String[] types;
    //这里的前缀就是服务位置+端口号
    private String prefix;

    @PostConstruct
    public void init() throws Exception {
        String path = new ClassPathResource("fdfs_client.conf").getFile().getAbsolutePath();
        ClientGlobal.init(path);
        trackerClient = new TrackerClient();
        trackerServer = trackerClient.getTrackerServer();
        storageServer = null;
        storageClient = new StorageClient1(trackerServer, storageServer);
        types = permitTypes.split(",");
        prefix = "http://" + trackerServer.getInetSocketAddress().getHostString()
                + ":" + ClientGlobal.getG_tracker_http_port() + "/";
    }

    /**
     * 上传输入流
     *
     * @param file 包装的文件数据
     * @return 文件路径
     */
    public String uploadFile(FastDFSFile file) throws Exception {
        //1.判定文件类型是否合法
        boolean permit = false;
        for (String type : types) {
            if (type.equals(file.getExt())) {
                permit = true;
                break;
            }
        }

        if (!permit) {
            String errMsg = "上传文件格式不允许";
            log.error(errMsg);
            throw new Exception(errMsg);
        }
        //2.封装参数
        NameValuePair[] metas = new NameValuePair[2];
        metas[0] = new NameValuePair("name", file.getName());
        metas[1] = new NameValuePair("author", file.getAuthor());
        //3.上传文件
        String relativePath = storageClient.upload_file1(file.getContent(), file.getExt(), metas);
        return prefix + relativePath;
    }

    /**
     * 删除文件
     *
     * @param filePath 文件路径
     * @return 返回操作结果判定
     * @throws IOException
     * @throws MyException
     */
    public boolean deleteFile(String filePath) throws IOException, MyException {
        return 0 == storageClient.delete_file1(StringUtils.replace(filePath, prefix, ""));
    }

    /**
     * 获取下载文件流
     *
     * @param filePath 文件完整路径
     * @return 返回输入流
     * @throws IOException
     * @throws MyException
     */
    public InputStream downloadFileStream(String filePath) throws IOException, MyException {
        byte[] content = storageClient.download_file1(filePath);
        return new ByteArrayInputStream(content);
    }

    /**
     * 获取下载文件Base64编码
     *
     * @param filePath 文件完整路径
     * @return 返回BASE64编码
     * @throws IOException
     * @throws MyException
     */
    public String downloadFileBase64(String filePath) throws IOException, MyException {
        try (InputStream inputStream = downloadFileStream(filePath)) {
            byte[] bytes = IOUtils.toByteArray(inputStream);
            String fileType = StringUtils.substringAfterLast(filePath, ".");
            String encodeStr = Base64.getEncoder().encodeToString(bytes);
            return String.format("data:image/%s;base64,", fileType) + encodeStr;
        } catch (Exception e) {
            return null;
        }
    }
}

```



-----



Controller代码：

```java
@RestController
@RequestMapping("fastdfs")
@Slf4j
public class FastDFSController {
    @Resource
    private FastDFSClient client;

    @PostMapping("upload")
    public RespVo<String> upload(MultipartFile file) {
        if (file == null) {
            return new RespVo<>(false, null, "文件不存在");
        }

        String filename = file.getOriginalFilename();
        if (StringUtils.isEmpty(filename)) {
            return new RespVo<>(false, null, "文件不存在");
        }

        try {
            String ext = filename.substring(filename.lastIndexOf(".") + 1);
            //TODO: 这里结合后面的权限校验把申请用户填进去
            FastDFSFile dfsFile = new FastDFSFile().setContent(file.getBytes()).setExt(ext).setName(filename).setAuthor("root");
            String fileDfsPath = client.uploadFile(dfsFile);
            return new RespVo<>(true, fileDfsPath, "文件上传成功");
        } catch (Exception e) {
            log.error("文件上传失败", e);
            return new RespVo<>(false, null, "文件上传失败");
        }
    }

    @GetMapping("delete")
    public RespVo<String> delete(@RequestParam("filePath") String filePath) throws IOException, MyException {
        if (client.deleteFile(filePath))
            return new RespVo<>(true, null, "文件删除成功");
        return new RespVo<>(false, null, "文件删除失败");
    }
}
```





#### 2.2.4 测试

验证文件：

```shell
#进入容器
docker exec -it storage /bin/bash

cd /etc/fdfs/
```





## 3 商品模型

根据业务不同，产商品模型的关联关系不同，这里采用B2C的模式构建产商品模型：



### 3.1 SPU

SPU: Standard Product Unit 标准产品单位，一般理解为一款商品。



这里使用的类目字段表示第三级类目，有的需求里面可以在任意类目下创建产品，也就是这里的`CATEGORY_ID`不一定是三级类别。

为了快速进行单表查询，一般不仅仅展示最后一级类目，会把三级的类别都作为字段存储。

```mysql
CREATE TABLE `SHOP_SPU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SPU_ID` varchar(64) DEFAULT NULL COMMENT 'SPU ID',
  `SPU_NAME` varchar(64) DEFAULT NULL COMMENT '名称',
  `TITLE` varchar(64) DEFAULT NULL COMMENT '标题',
  `SPU_PIC_URL` varchar(2000) DEFAULT NULL COMMENT '图片地址',
  `DESCRIPTION` varchar(512) DEFAULT NULL COMMENT '描述',
  `CATEGORY_ID` varchar(36) NOT NULL COMMENT '三级类别ID',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '上下架状态，0新建，1已下架，2已上架',
  `IS_HOT` tinyint(1) NOT NULL DEFAULT '0' COMMENT '是否是热销产品，0否，1是',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `LIST_TIME` datetime DEFAULT NULL COMMENT '上架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELIST_TIME` datetime DEFAULT NULL COMMENT '下架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
      PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PRODUCT_ID_INDEX` (`SPU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SPU产品数据';
```



### 3.2 SKU

SKU: Stock Keeping Unit 库存单位，通过SPU指定规格参数生产，一般理解为最小销售/库存单位。



一般为了快速进行单表查询，也会把类别、品牌、评价数的字段加到表里面

```mysql
CREATE TABLE `SHOP_SKU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU ID',
  `SPU_ID` varchar(64) NOT NULL COMMENT '关联SPU ID',
  `PRICE` int(9) NOT NULL DEFAULT '0' COMMENT '价格,单位：分',
  `QUANTITY` int(4) DEFAULT NULL COMMENT '库存数量',
  `SKU_PIC_URL` varchar(256) DEFAULT NULL COMMENT '图片地址',
  `STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '上下架状态，0新建，1已下架，2已上架',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建日期（格式：yyyy-MM-dd HH:mm:ss）',
  `LIST_TIME` datetime DEFAULT NULL COMMENT '上架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELIST_TIME` datetime DEFAULT NULL COMMENT '下架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改日期（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT 'sku最后修改人',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SKU_ID_INDEX` (`SKU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU商品表';
```



### 3.3 类别、参数与自定义参数

**类别表：**

```mysql
CREATE TABLE `SHOP_CATEGORY` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(36) NOT NULL COMMENT '类别ID',
  `CATEGORY_NAME` varchar(128) NOT NULL COMMENT '类别名称',
  `CATEGORY_LEVEL` tinyint(2) NOT NULL DEFAULT '0' COMMENT '类别等级',
  `PARENT_ID` varchar(36) DEFAULT NULL COMMENT '父ID（一级分类的 PARENT_ID = 0）',
  `SORT` int(11) DEFAULT NULL COMMENT '排序',
  `REMARK` varchar(512) DEFAULT NULL COMMENT '备注',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `CATEGORY_STATUS` tinyint(1) NOT NULL DEFAULT '1' COMMENT '状态，0禁用，1启用',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `CATEGORY_ID_INDEX` (`CATEGORY_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别表';
```



-----



**参数表：**

```mysql
CREATE TABLE `SHOP_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `PARAM_ID` varchar(64) NOT NULL COMMENT '参数ID',
  `PARAM_TYPE` tinyint(1) NOT NULL COMMENT '类型（0规格属性，1其他属性）',
  `PARAM_NAME` varchar(64) NOT NULL COMMENT '名称',
  
  `ORDER_NUM` int(11) DEFAULT '0' COMMENT '排序',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`PARAM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='参数表';
```

对应下面这张图来看：`PARAM_TYPE`这个字段主要还是区分**规格参数**和sku之间有差别的参数（其他参数）。

**规格参数**是指能够区分出sku的参数。具体来说，产品关联了类别id，找到对应的规格参数，通过勾选规格参数的笛卡尔积生成SKU。

**其他参数**在很多业务上是不需要的，因为大多数时间产商品都是同一类，如下图像库存数量、重量都是必填项，属于SKU表中的固定字段，但是如果我们的商城还存在没有重量、库存这种指标的商品（比如视频、游戏账号），那么可以把这些参数作为其他参数。

<img src="./images/规格参数与sku.png" style="zoom: 50%;" />



**参数类别关联：**规格参数和类别关联起来，根据业务决定是只能在三级类别上面挂载参数还是任意级别。

```mysql
CREATE TABLE `SHOP_CATEGORY_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(64) NOT NULL COMMENT 'CATEGORY_ID',
  `PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`CATEGORY_ID`,`PARAM_ID`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别-参数关联';
```

这里参数是关联的类别，使用SPU关联类别来找到参数。

根据需求有时候可能会在SPU这个级别重新制定参数，也就是类别的参数可能只是作为一个选择，那么我们只选定SPU需要的参数，这个时候需要再有一个关联SPU和参数的表。



----



**自定义参数表：**

**自定义参数**作为sku规格以外的*补充参数*（比如生产厂商、物流仓库地址等不影响价格的因素，当然最重要的是不影响sku库存最小单位）。

这个表设计和参数表一样，需要挂载到类别上面，作为SPU级别的补充参数。

```mysql
CREATE TABLE `SHOP_CUSTOM_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CUSTOM_PARAM_ID` varchar(64) NOT NULL COMMENT '自定义参数ID',
  `CUSTOM_PARAM_NAME` varchar(64) NOT NULL COMMENT '名称',
  
  `ORDER_NUM` int(11) DEFAULT '0' COMMENT '排序',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `CUSTOM_PARAM_ID_INDEX` (`CUSTOM_PARAM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='自定义参数表';

CREATE TABLE `SHOP_CATEGORY_CUSTOM_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(64) NOT NULL COMMENT 'CATEGORY_ID',
  `CUSTOM_PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`CATEGORY_ID`,`PARAM_ID`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别-参数关联';
```





**SKU参数值关联：**

以前很多项目喜欢使用json的格式来保存像规格参数这种数据，实际上为了快速进行单表查询，可以把这种字段作为冗余保存在sku的表中，但是为了方便对参数进行定义和CRUD，最好还是把这些数据作为单独的表分割出来。

所以我们可以通过SKU_ID关联到属性值：

```mysql
CREATE TABLE `SHOP_SKU_PARAM_VALUE` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU的ID',
  `PARAM_VALUE_ID` varchar(64) NOT NULL COMMENT '参数值ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SKU_PARAM_VALUE_ID_UKEY` (`SKU_ID`,`PARAM_VALUE_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU - 参数值表';
```



**参数值：**

```mysql
CREATE TABLE `SHOP_PARAM_VALUE` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `PARAM_VALUE_ID` varchar(64) NOT NULL COMMENT 'PARAM_VALUE_ID',
  `PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  `PARAM_VALUE` varchar(256) NOT NULL COMMENT '产品属性值',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_VALUE_ID_INDEX` (`PARAM_VALUE_ID`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=896 DEFAULT CHARSET=utf8 COMMENT='参数值表';
```



### 3.4 厂家与SKU关联表

涉及到库存考虑的点比较多，比如如果是单一商家不仅有库存表，还会有供应商和spu进行关联，用户可以选择发货地最近的供货商和厂库。

但是相同的是，都需要保持一个sku与厂家的关系，这里是简化的数据设计，只做关系映射表方便后面进行拆单的业务模拟：

```sql
DROP TABLE IF EXISTS `SHOP_STORE_SKU`;
CREATE TABLE `SHOP_STORE_SKU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `STORE_ID` varchar(64) NOT NULL COMMENT '厂家ID',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SHOP_STORE_SKU_ID_UKEY` (`STORE_ID`,`SKU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU - 厂家关联表';
```





## 4 缓存实现-首页广告位示例

### 4.1基本思路

首页的内容对响应速度敏感，所以我们需要使用缓存存储首页广告位。

<img src="./images/广告缓存方案.png" style="zoom:67%;" />



### 4.2表结构

```mysql
CREATE TABLE `SHOP_AD_CONTENT` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `AD_ID` varchar(64) NOT NULL COMMENT '广告ID',
  `AD_CATEGORY_ID` varchar(64) NOT NULL COMMENT '广告类目ID',
  `AD_TITLE` varchar(256) NOT NULL COMMENT '标题',
  `AD_URL` varchar(256) DEFAULT NULL COMMENT '连接地址',
  `AD_PIC_URL` varchar(256) DEFAULT NULL COMMENT '图片地址',
  `AD_STATUS` tinyint(1) NOT NULL DEFAULT '1' COMMENT '状态，0禁用，1启用',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `AD_ID_INDEX` (`AD_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='广告表';

CREATE TABLE `SHOP_AD_CATEGORY` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `AD_CATEGORY_ID` varchar(64) NOT NULL COMMENT '广告类目ID',
  `AD_CATEGORY_NAME` varchar(256) NOT NULL COMMENT '广告类目名称',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `AD_CATEGORY_ID_INDEX` (`AD_CATEGORY_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='广告类目表';
```



### 4.2 Lua脚本语言

轻量脚本语言，c编写主要是为了提供扩展定制功能（脚本的另外一种说法）。

参考学习： https://www.runoob.com/lua/lua-tutorial.html 

特点：

- 支持面向过程 (Procedure Oriented)和函数式编程(Functional Programming)  
- 仅使用通用类型的表
- 闭包



**安装**

```shell
#相关依赖库安装
yum install ‐y gcc
yum install libtermcap‐devel ncurses‐devel libevent‐devel readline‐devel

#获取包并解压
curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz
tar xzvf lua-5.3.0.tar.gz 

#安装
cd lua-5.3.0
make linux test
make install

#测试
lua
```



**执行**

可以使用文件执行：

```shell
vim hello.lua
#内容
print("hello world")

#执行
lua hello.lua
```



也可以直接`lua`命令进入控制台写



**注释**

```lua
--这是单行注释
--[[
这是多行注释
--]]
```



**关键字**

|          |       |       |        |
| -------- | ----- | ----- | ------ |
| and      | break | do    | else   |
| elseif   | end   | false | for    |
| function | if    | in    | local  |
| nil      | not   | or    | repeat |
| return   | then  | true  | until  |
| while    | goto  |       |        |



**变量**

```lua
--全局变量
a=1
--局部变量
local a=1
--变量没有赋值为 nil ，同样删除变量只需要赋值为 nil
a=nil
```



**数据类型**

 Lua 是动态类型语言，不用类型定义。 

| 数据类型 | 描述                                                         |
| :------- | :----------------------------------------------------------- |
| nil      | 无效值（在条件表达式中相当于false，做比较如x == "nil" 需要加双引号）。 |
| boolean  | 包含两个值：false和true。                                    |
| number   | 表示双精度类型的实浮点数                                     |
| string   | 字符串由一对双引号或单引号来表示                             |
| function | 由 C 或 Lua 编写的函数                                       |
| userdata | 表示任意存储在变量中的C数据结构                              |
| thread   | 表示执行的独立线路，用于执行协同程序                         |
| table    | Lua 中的表（table）其实是一个"关联数组"（associative arrays），数组的索引可以是数字、字符串或表类型。在 Lua 里，table 的创建是通过"构造表达式"来完成，最简单构造表达式是{}，用来创建一个空表。 |



测试：

```lua
print(type("Hello world"))      --> string
print(type(10.4*3))             --> number
print(type(print))              --> function
print(type(type))               --> function
print(type(true))               --> boolean
print(type(nil))                --> nil
print(type(type(X)))            --> string
```



**流程控制**

```lua
--if语句
if(布尔表达式)
then
   --[ 在布尔表达式为 true 时执行的语句 --]
end

--if else
if(布尔表达式)
then
   --[ 布尔表达式为 true 时执行该语句块 --]
else
   --[ 布尔表达式为 false 时执行该语句块 --]
end

--if嵌套
if( 布尔表达式 1)
then
   --[ 布尔表达式 1 为 true 时执行该语句块 --]
   if(布尔表达式 2)
   then
      --[ 布尔表达式 2 为 true 时执行该语句块 --]
   end
end
```



**循环**

同样的可以使用`goto`和`break`

```lua
--while循环
while(condition)
do
   statements
end

--for循环
--[[
var 从 exp1 变化到 exp2，每次变化以 exp3 为步长递增 var，并执行一次 "执行体"。exp3 是可选的，如果不指定，默认为1。
--]]
for var=exp1,exp2,exp3 do  
    <执行体>  
end  

--特殊的有，可以遍历输出 ipairs是Lua提供的一个迭代器函数，用来迭代数组。
#!/usr/local/bin/lua  
days = {"Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"}  
for i,v in ipairs(days) do  print(v) end  

--repeat until
repeat
   statements
until( condition )
```





嵌lua套循环：

```lua
for init,max/min value, increment
do
   for init,max/min value, increment
   do
      statements
   end
   statements
end

while(condition)
do
   while(condition)
   do
      statements
   end
   statements
end

repeat
   statements
   repeat
      statements
   until( condition )
until( condition )
```



**函数**

```lua
optional_function_scope function function_name( argument1, argument2, argument3..., argumentn)
    function_body
    return result_params_comma_separated
end

-- optional_function_scope:			全局 或者 局部（使用local）
-- result_params_comma_separated: 	函数返回值可以使用逗号隔开
```



例子：

```lua
function maximum (a)
    local mi = 1             -- 最大值索引
    local m = a[mi]          -- 最大值
    for i,val in ipairs(a) do
       if val > m then
           mi = i
           m = val
       end
    end
    return m, mi
end

print(maximum({8,10,23,12,5}))
```



可以使用`...`表示可变长参数

使用` select('#',...)`获取参数长度

使用` select(n,...)`获取第n个参数

```lua
do  
    function foo(...)  
        for i = 1, select('#', ...) do  -->获取参数总数
            local arg = select(i, ...); -->读取参数
            print("arg", arg);  --还可以紧密拼接 print("arg"..arg)
        end  
    end  
 
    foo(1, 2, 3, 4);  
end
--[[
输出：
arg    1
arg    2
arg    3
arg    4
--]]
```



**表**

```lua
-- 初始化表
mytable = {}

-- 指定值
mytable[1]= "Lua"

-- 移除引用 垃圾回收会释放内存
mytable = nil
```



**模块**

定义模块：

```lua
-- 文件名为 module.lua
-- 定义一个名为 module 的模块
module = {}
 
-- 定义一个常量
module.constant = "这是一个常量"
 
-- 定义一个函数
function module.func1()
    io.write("这是一个公有函数！\n")
end

local function func2()
    print("这是一个私有函数！")
end
 
function module.func3()
    func2()
end
 
return module
```



加载使用：

```lua
--[[
require("<模块名>")
或者
require "<模块名>"
--]]
--直接使用
require("module")
print(module.constant)
module.func3()

--定义别名使用
m = require("module")
print(m.constant)
m.func3()
```



### 4.3 OpenResty

基于nginx的可伸缩Web平台，外部人员可以通过lua脚本调用nginx内置模块。

https://github.com/openresty



#### 4.3.1 安装OpenResty

linux安装OpenResty：

```shell
#添加仓库执行命令
yum install yum-utils
yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo

#执行安装，会安装在默认的路径下/usr/local/openresty
yum -y install openresty
```



#### 4.3.2 Nginx

##### 4.3.2.1 安装

安装了openresty后默认会在目录下安装nginx，下面是复制的以前的笔记做备忘。

```shell
#编译工具与库文件
yum -y install make zlib zlib-devel gcc-c++ libtool  openssl openssl-devel

#安装PCRE可以让nginx支持Rewrite功能
cd /usr/local/src/
#建议本地下，太卡了
wget https://netix.dl.sourceforge.net/project/pcre/pcre/8.40/pcre-8.40.tar.gz
tar zxvf pcre-8.40.tar.gz
cd pcre-8.40
./configure
make && make install
#查看pcre版本
pcre-config --version

#安装nginx
cd /usr/local/src/
wget http://nginx.org/download/nginx-1.6.2.tar.gz
tar zxvf nginx-1.6.2.tar.gz
cd nginx-1.6.2
./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.40
make
make install
#查看版本
/usr/local/webserver/nginx/sbin/nginx -v

#nginx环境变量设置
vim /etc/profile
#内容
export PATH=$PATH:/usr/local/webserver/nginx/sbin/
#生效
source /etc/profile
nginx -v
```



##### 4.3.2.2 基础命令

```shell
#重载
nginx -s reload

#停止
nginx -s stop

#指定配置文件
nginx -c /usr/local/webserver/nginx/conf/nginx.conf
```

启动后可以直接访问ip:80



##### 4.3.2.3 启动OpenResty

```shell
/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf
```

<img src="./images/openresty界面.png" style="zoom:67%;" />





### 4.4 测试：数据更新到缓存实现

我们设定用户的请求为：`update_ad?categoryId=xxx`



#### 4.4.1 lua脚本

把数据从mysql查询出来保存到缓存中：

`vim /root/lua-5.3.0/zscript/update_ad.lua`



```lua
ngx.header.content_type="application/json;charset=utf8"
local cjson = require("cjson")
local mysql = require("resty.mysql")

local uri_args = ngx.req.get_uri_args()
local categoryId = uri_args["categoryId"]

local db = mysql:new()
db:set_timeout(1000)
local props = {
	host = "192.168.190.200",
	port = 3306,
	database = "shop_ad",
	user = "root",
	password = "123456"
}

local res = db:connect(props)
local select_sql = "SELECT AD_TITLE, AD_URL, AD_PIC_URL FROM SHOP_AD_CONTENT WHERE AD_STATUS = '1' AND AD_CATEGORY_ID= '"..categoryId.."' "
res = db:query(select_sql)
db:close()

local redis = require("resty.redis")
local red = redis:new()
red:set_timeout(2000)
local ip ="192.168.190.200"
local port = 6379
red:connect(ip,port)
red:auth("123456")
red:set("ad_"..categoryId,cjson.encode(res))
red:close()

ngx.say("{flag:true}")
```



#### 4.4.2 nginx配置

server下面添加：

```nginx
server{
	listen 80;
    server_name localhost;
    
    #把用于请求update_ad?categoryId=xxx交给脚本处理
    #脚本地址：/root/lua-5.3.0/zscript/update_ad.lua
    location /update_ad {
        content_by_lua_file /root/lua-5.3.0/zscript/update_ad.lua;
    }
}
```



完成之后重启nginx：

```shell
/usr/local/openresty/nginx/sbin/nginx -s reload
```



#### 4.4.3 脚本访问权限

如果直接访问会返回404，之后查看nginx日志：

```shell
tail -f /usr/local/openresty/nginx/logs/error.log
cannot open /root/lua-5.3.0/zscript/update_ad.lua: Permission denied, 
```



需要在nginx的配置文件上加上用户配置：

```shell
vim /usr/local/openresty/nginx/conf/nginx.conf

#user  nobody;
user root root;
```



完成之后重启nginx：

```shell
/usr/local/openresty/nginx/sbin/nginx -s reload
```



测试：

http://192.168.190.200/update_ad?categoryId=3



### 4.5 读取缓存数据

完整的路径应该是首选获取nginx缓存，如果缓存不存在获取redis缓存，不存在获取mysql数据。

我们设定用户的请求为：`read_ad?categoryId=xxx`

#### 4.5.1 lua脚本

`vim /root/lua-5.3.0/zscript/read_ad.lua`



这里的`ngx.shared.dis_cache`是定义的nginx缓存模块

```lua
ngx.header.content_type="application/json;charset=utf8"
local uri_args = ngx.req.get_uri_args()
local categoryId = uri_args["categoryId"]

local cache_ngx = ngx.shared.dis_cache;
local contentCache = cache_ngx:get('ad_cache_'..categoryId);
ngx.say('nginx',contentCache)

if contentCache == "" or contentCache == nil then
    local redis = require("resty.redis")
    local red = redis:new()
    red:set_timeout(2000)
    red:connect("192.168.190.200",6379)
    red:auth("123456")
    --单位ms
    red:set_timeout(2*60*1000)
    local rescontent = red:get("ad_"..categoryId)
    ngx.say('redis',rescontent)
    
    if ngx.null == rescontent then
        local cjson = require("cjson")
		local mysql = require("resty.mysql")
		local db = mysql:new()
		db:set_timeout(1000)
        local props = {
            host = "192.168.190.200",
            port = 3306,
            database = "shop_ad",
            user = "root",
            password = "123456"
        }
		local res = db:connect(props)
        local select_sql = "SELECT AD_TITLE, AD_URL, AD_PIC_URL FROM SHOP_AD_CONTENT WHERE AD_STATUS = '1' AND AD_CATEGORY_ID= '"..categoryId.."' "
		res = db:query(select_sql)
        local resJson = cjson.encode(res)
        red:set("ad_"..categoryId,resJson)
        ngx.say('mysql',resJson)
		db:close()
    else
        -- nginx缓存1分钟
        cache_ngx:set('ad_cache_'..categoryId, rescontent, 1*60)
        ngx.say(rescontent)
    end
    red:close()
else
    ngx.say(contentCache)
end
```



#### 4.5.2 nginx配置

`vim /usr/local/openresty/nginx/conf/nginx.conf`



我们需要添加缓存模块和路由信息：

```nginx
user root root;
worker_processes  1;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #cache:定义缓存模块，大小为128M
    lua_shared_dict dis_cache 128m;

    sendfile        on;
    keepalive_timeout  65;

    server {
        listen       80;
        server_name  localhost;

        location / {
            root   html;
            index  index.html index.htm;
        }

        location /read_ad {
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```



重启：`/usr/local/openresty/nginx/sbin/nginx -s reload`





### 4.6 nginx限流

实现方式：

- 控制速率
- 控制并发连接数



#### 4.6.1 控制速率



##### 4.6.1.1 拒绝超出响应的请求

`vim /usr/local/openresty/nginx/conf/nginx.conf`



```nginx
http{
    ......
    
    #限流设置 binary_remote_addr根据请求地址进行限流
    #contentRateLimit 缓存空间名称，大小为10M
    #rate=2r/s 每秒两个请求
    limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s;
    
    server{
         location /read_ad {
            #使用限流配置
            limit_req zone=contentRateLimit;
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
    }
}
```

>binary_remote_addr 是一种key，表示基于 remote_addr(客户端IP) 来做限流，binary_ 的目的是压缩内存占用量。
>
>zone：定义共享内存区来存储访问信息， myRateLimit:10m 表示一个大小为10M，名字为myRateLimit的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。
>
>rate 用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求.我们这里设置成2 方便测试。



重启测试：`./nginx -s reload`

<img src="./images/nginx限流错误-浏览器.png" style="zoom:67%;" />

访问错误日志：

`2020/08/28 01:05:48 [error] 1642#1642: *31 limiting requests, excess: 0.300 by zone "contentRateLimit", client: x.x.x.x, server: localhost, request: "GET /read_ad?categoryId=1 HTTP/1.1", host: "192.168.190.200"`



##### 4.6.1.2 处理突发流量

在上面的例子`rate=2r/s`，也就是500ms只能处理一个请求，但是如果我们希望处理突发流量，把多余的请求先放入队列等待。

我们可以在`limit_req`后面加入`burst`字段，如下：

`limit_req zone=contentRateLimit burst=20;`

如果同时进入21个请求，那么多余的20个请求将会进入队列等待。当然如果超出21个请求，多余的会被拒绝。



当然，如果一直排队也会出现等待时间过长，比如这里的500ms处理一个请求，那么队列中最后一个请求要等待到10s之后了，我们可以加入`nodelay`参数：

```nginx
http{
    ......
    
    #限流设置 binary_remote_addr根据请求地址进行限流
    #contentRateLimit 缓存空间名称，大小为10M
    #rate=2r/s 每秒两个请求
    limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s;
    
    server{
         location /read_ad {
            #使用限流配置
            limit_req zone=contentRateLimit burst=5 nodelay;
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
    }
}
```

此时如果同时有6个请求到达，那么队列中还有位置，nginx就会立即转发（想防御这6个事并行处理的），超出缓冲队列的请求会直接拒绝。



#### 4.6.2 控制并发量

`ngx_http_limit_conn_module`提供了并发量控制的能力，主要是利用`limit_conn_zone`和`limit_conn`两个指令，利用连接数限制某一个用户的**IP连接数量**来控制流量。



注意：只有服务器正在处理请求并且已经读取了整个请求头的时候，才会计算为有效连接。



##### 4.6.2.1 单个IP并发限制

编写本地测试接口：

端口8001，ip：192.168.190.1

```java
@RestController
public class TestController {
    @GetMapping("sleep")
    public String sleep() {
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return "sleep";
    }
}
```





配置nginx到本地测试：

```nginx
http{
	......
    #根据IP地址来限制，存储内存大小为10M addr是命名
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    
    server{
        ......
        #转发到本地测试接口
        location /sleep {
            #配置addr，表示每秒可以有两个请求
            limit_conn addr 2;
            proxy_pass http://192.168.190.1:8001/sleep;
        }
    }
}
```



使用JMeter测试可以看出来，每s第三个请求直接失败。



##### 4.6.2.2 固定接口并发限制

我们之前是通过对统一IP地址进行访问并发的限制，同时，我们可以对所有的请求也进行并发限制。

采用之前的接口来做测试，增加nginx的配置：

```nginx
http{
	......
    #根据IP地址来限制，存储内存大小为10M addr是命名
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    #对固定接口限制总的并发量
    limit_conn_zone $server_name zone=curserver:10m;
    
    server{
        ......
        #转发到本地测试接口
        location /sleep {
            #配置addr，表示每秒可以有两个请求
            limit_conn addr 2;
            #配置curserver，表示每s这个接口总共可以接收10个请求
            limit_conn curserver 10;
            proxy_pass http://192.168.190.1:8001/sleep;
        }
    }
}
```

也就是说，每秒sleep接口可以访问10次，但是来源于同一IP的请求只能有2个。



### 4.7 Canal同步数据

只要是有关缓存的问题就会涉及到数据的更新，不管我们是定时更新缓存数据还是在变化的时候马上写缓存，都存在一定的问题（更新不及时或者消耗接口时间）。同样的，在这个例子里面，我们希望有一个服务能够监听数据的更改，实时刷新缓存。



使用之前，我们需要在mysql里面开启日志



#### 4.7.1 工作原理

有关canal的介绍可以看官方的文档：https://github.com/alibaba/canal

<img src="./images/mysql主备复制原理.jpg" style="zoom: 80%;" />

上图展示了mysql的主从复制原理：

- MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看)
- MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)
- MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据



canal 工作原理

- canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
- MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
- canal 解析 binary log 对象(原始为 byte 流)



<img src="./images/Canal原理.png" style="zoom: 60%;" />

canal获取到数据之后，可以把数据刷新到Redis缓存中，在其他地方，也可以把数据写入ES、MySQL等处理。



#### 4.7.2 mysql开启binlog模式和创建同步账号

**开启binlog模式**

 我们这里是用docker安装的mysql，所以里面基本的环境都没有，可以使用` apt-get update`和`apt-get install vim`来安装vim

```shell
#进入mysql容器
docker exec -it z-mysql /bin/bash

#连接
mysql -h localhost -uroot -p123456

#查看mysql是否开启binlog模式，也就是log_bin的值如果ON则是开启
SHOW VARIABLES LIKE '%log_bin%';

#修改配置文件
vim /etc/mysql/mysql.conf.d/mysqld.cnf

[mysqld]
......

#binlog setting,第一个log-bin是二进制存储目录，第二个是当前数据库的唯一编号
log-bin=/var/lib/mysql/mysql-bin #开启 binlog
binlog-format=ROW #选择 ROW 模式
server-id=12345 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复

#修改完成之后，重启mysql服务或者直接docker restart z-mysql
/etc/init.d/mysql restart
```



**创建同步账号**

使用root账号创建用户并授权：

```shell
#进入mysql容器
docker exec -it z-mysql /bin/bash

#进入mysql
mysql -h localhost -uroot -p123456

#创建账号用于同步数据
#创建账号，账号名密码canal，'%'表示可以从任意主机登录
create user 'canal'@'%' IDENTIFIED by 'canal';
#授权：*.*表示所有数据库所有表
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT, SUPER ON *.* TO 'canal'@'%';
#权限生效
FLUSH PRIVILEGES;
```



#### 4.7.3 Canal容器安装

```powershell
#下载镜像
docker pull canal/canal-server

#创建容器
docker run -p 11111:11111 --name z-canal -d canal/canal-server 

#设置自启动
docker update --restart=always z-canal

#进入容器
docker exec -it z-canal /bin/bash

pwd
/home/admin
yum -y install vim

------------------------------------------------
#修改canal自身配置
vim canal-server/conf/canal.properties

#这里的id和mysql里面的server-id都表示服务的id，不能和mysql的server-id重复
canal.id = 1

------------------------------------------------
#同步配置
vim canal-server/conf/example/instance.properties

# 指定需要同步的数据库地址
# position info
canal.instance.master.address=192.168.190.200:3306

canal.instance.dbUsername=canal
canal.instance.dbPassword=canal

#数据库表的正则匹配，这里表示所有数据库(.*)所有表(.*)，中间(\\.)转义.
# table regex
canal.instance.filter.regex=.*\\..*


#配置完成后重启
docker restart z-canal
#也可以直接在容器里面重启
canal-server/bin/stop.sh
canal-server/bin/startup.sh
```



#### 4.7.4 查看日志

- 查看server日志：`tail -f canal-server/logs/canal/canal.log`
- 查看instance日志：`tail -f canal-server/logs/example/example.log`



#### 4.7.5 搭建canal微服务



##### 4.7.5.1 基础配置

pom依赖：使用github上面的依赖https://github.com/chenqian56131/spring-boot-starter-canal.git

```xml
        <dependency>
            <groupId>com.xpand</groupId>
            <artifactId>starter-canal</artifactId>
            <version>0.0.1-SNAPSHOT</version>
        </dependency>
```



配置文件：`application.yml`

```yaml
server:
  port: 8002
spring:
  application:
    name: canal-service
eureka:
  client:
    service-url:
      defaultZone: http://test:123456@127.0.0.1:8000/eureka/
  instance:
    prefer-ip-address: true
feign:
  hystrix:
    enabled: true
#canal配置
canal:
  client:
    instances:
      example:
        host: 192.168.190.200
        port: 11111
```





启动类：

```java
@SpringBootApplication
@EnableCanalClient
@EnableEurekaClient
public class CanalApplication {
    public static void main(String[] args) {
        SpringApplication.run(CanalApplication.class);
    }
}
```



##### 4.7.5.1 监听类

```java
package com.zr.canal.demo;

import com.alibaba.fastjson.JSONObject;
import com.alibaba.otter.canal.protocol.CanalEntry;
import com.xpand.starter.canal.annotation.*;
import lombok.extern.slf4j.Slf4j;

import java.util.List;

/**
 * Description:
 * 测试Canal 数据监听
 *
 * @author zhangr
 * 2020/8/31 16:56
 */
@CanalEventListener
@Slf4j
public class TestListener {
    //增加监听，需要看操作之后的数据
    @InsertListenPoint
    public void onEventInsert(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getAfterColumnsList())
            log.info("增加操作：{} : {}", column.getName(), column.getValue());
    }

    //更新监听，需要看操作之后的数据
    @UpdateListenPoint
    public void onEventUpdate(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getBeforeColumnsList())
            log.info("更新操作 修改前：{} : {}", column.getName(), column.getValue());

        for (CanalEntry.Column column : rowData.getAfterColumnsList())
            log.info("更新操作 修改后：{} : {}", column.getName(), column.getValue());
    }

    //删除监听，需要看操作之前的数据
    @DeleteListenPoint
    public void onEventDelete(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getBeforeColumnsList())
            log.info("删除操作：{} : {}", column.getName(), column.getValue());
    }

    //自定义监控：指定监听的类型、数据库、表、实例地址
    @ListenPoint(
            eventType = {CanalEntry.EventType.DELETE, CanalEntry.EventType.INSERT},
            schema = {"shop_ad"},
            table = {"SHOP_AD_CONTENT"},
            destination = "example"
    )
    public void onEventCustomize(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getBeforeColumnsList())
            log.info("自定义操作 修改前：{} : {}", column.getName(), column.getValue());

        for (CanalEntry.Column column : rowData.getAfterColumnsList())
            log.info("自定义操作 修改后：{} : {}", column.getName(), column.getValue());
    }

}
```





## 5 商品搜索（ES）

这里因为资源的问题（docker下载太慢）还是按照网上教程的5.6.8的版本，对于新的版本（7）来说type已经被舍弃，也就是说实际上我们把index当做表维度而不是type，之前的数据如果需要迁移升级需要创建index。



### 5.1 docker安装ElasticSearch

es占用内存挺大的，可以先使用`free -h`看一下是否需要扩容：

```shell
#docker镜像下载
docker pull elasticsearch:5.6.8

#创建容器，其中9200是es与外部的通信端口，9300则是集群通信端口
docker run -id --name=z-es -p 9200:9200 -p 9300:9300 elasticsearch:5.6.8

#设置开机自启
docker update --restart=always z-es
```



测试访问：http://192.168.190.200:9200

```json
{
  "name" : "gWEiSMM",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "pPA-UIujQf661oDHIIKAzQ",
  "version" : {
    "number" : "5.6.8",
    "build_hash" : "688ecce",
    "build_date" : "2018-02-16T16:46:30.010Z",
    "build_snapshot" : false,
    "lucene_version" : "6.6.1"
  },
  "tagline" : "You Know, for Search"
}
```



ES从5版本以后默认不开启远程连接，客户端程序直接连接会报错。

我们需要修改ES配置开启远程连接：

```shell
#进入容器
docker exec -it z-es /bin/bash

#修改配置文件，没有vim使用apt-get update 和 apt-get install vim
vim /usr/share/elasticsearch/config/elasticsearch.yml

#去掉这一行的注释
transport.host: 0.0.0.0
#添加集群名称
cluster.name: my-application
#开启跨域
http.cors.enabled: true
#允许的域
http.cors.allow-origin: "*"
network.host: 192.168.190.200

#重启docker
docker restart z-es
```



此时可能会重启报错，因为我们放开了更多的配置，导致需要打开更多的文件和内存空间，因此我们需要修改一些系统调优的配置：

```shell
vim /etc/security/limits.conf

#追加配置，nofile单个进程允许打开的最大文件数
#soft nofile软限制
#hard nofile硬限制
* soft nofile 65536
* soft nofile 65536

-------------------------------

vim /etc/sysctl.conf

#追加配置，限制一个进程可以拥有的VMA（虚拟内存区域）数量
vm.max_map_count=655360

#执行下面命令 修改内核参数立即生效
sysctl -p

#重启虚拟机，即可访问
reboot
```





如果内存吃紧，可以把里面的jvm内存配置减小：

```shell
docker exec -it z-es /bin/bash

vim /etc/elasticsearch/jvm.options
-Xms1g
-Xmx1g
```



### 5.2 IK分词器安装

下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases

```shell
#下载后上传到服务器解压
unzip elasticsearch-analysis-ik-5.6.8.zip

#解压后修改文件名为ik
mv elasticsearch ik

#将文件复制到容器里面
docker cp ./ik z-es:/usr/share/elasticsearch/plugins

#重启容器
docker restart z-es
```



测试：

http://192.168.190.200:9200/_analyze?analyzer=ik_smart&pretty=true&text=狮子吃羚羊

显示结果：

```json
{
  "tokens" : [
    {
      "token" : "狮子",
      "start_offset" : 0,
      "end_offset" : 2,
      "type" : "CN_WORD",
      "position" : 0
    },
    {
      "token" : "吃",
      "start_offset" : 2,
      "end_offset" : 3,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "羚羊",
      "start_offset" : 3,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 2
    }
  ]
}
```





自定义分词器：

在我们刚刚操作的ik文件里面修改配置文件

` vim /usr/share/elasticsearch/plugins/ik/config/IKAnalyzer.cfg.xml`

可以添加自定义分词文件，也可以停用词汇文件。



### 5.3 docker安装kibana

为了数据可视化，使用kibana数据分析统计工具。



```shell
#拉镜像
docker pull kibana:5.6.8

#创建容器 -e配置环境变量
docker run -itd -e ELASTICSEARCH_URL=http://192.168.190.200:9200 --name z-kibana --restart=always -p 5601:5601 kibana:5.6.8
```



测试地址：192.168.190.200:5601



进去之后可以看到要求配置索引：

![](./images/kibana初始界面.png)

 

这里后面在es里面创建索引之后就可以配置了。



### 5.4 DSL

下面这些操作都是在Kibana Dev Tools里面进行的，也可以直接使用curl操作。

具体语法如下：

```sh
curl -X<VERB> '<PROTOCOL>://<HOST>:<PORT>/<PATH>?<QUERY_STRING>' -d '<BODY>'

如：curl -X PUT “http://192.168.190.200:9200/adinfo/_mapping” -H 'Content-Type:application.json' -d '
{
	......
}
'
```



#### 5.4.1 索引

```sh
#查询全部索引
GET _cat/indices?v
GET _all

#创建索引，索引名必须小写
PUT /skuinfo

#查看指定索引
GET /skuinfo
GET /skuinfo,adinfo

#删除
DELETE /skuinfo

#关闭
POST /adinfo/_close

#打开
POST /adinfo/_open
```



#### 5.4.2 映射

```shell
#创建，这里的top就是type这个字段，现在新的版本被舍弃了
PUT adinfo/_mapping/top
{
 "properties":{
   "cat":{
     "type": "text",
     "analyzer": "ik_smart",
     "search_analyzer": "ik_smart"
   },
   "title":{
     "type": "text",
     "analyzer": "ik_smart",
     "search_analyzer": "ik_smart"
   },
   "sort_no":{
     "type": "long"
   }
 }  
}

#获取
GET adinfo/_mapping/top
```



#### 5.4.3 文档（数据）

新的版本会撤销这个type（实际变化不大），使用`_doc`代替所有的类型，所以也称为文档。

```sh
#添加数据，这里的1作为id，如果新版本没有type，写成PUT adinfo/_doc/1{}
#id相同的情况，删除原始数据再新增
PUT adinfo/top/1
{
  "cat": "类目1",
  "title": "电器广告1",
  "sort_no": "1"
}

#只能创建数据
#或者使用自动生成id，默认自动创建索引是开启的
POST adinfo/top
{
  "cat": "手机",
  "title": "小米手机",
  "sort_no": "100"
}

#查看
GET adinfo/top/1

#更新指定域
POST adinfo/top/1/_update
{
  "doc": {
    "cat": "类目2"
  } 
}

#删除
DELETE adinfo/top/1

#查看全部数据
GET adinfo/_search
GET adinfo/top/_search
```



#### 5.4.4 查询

```sh
#排序查询
GET adinfo/top/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "sort_no": {
        "order": "desc"
      }
    }
  ],
  "from": 0,
  "size": 2
}

#过滤查询
GET adinfo/top/_search
{
  "query": {
    "term": {
      "title": {
        "value": "华为"
      }
    }
  }
}

#多个term搜索
GET adinfo/top/_search
{
  "query": {
    "terms": {
      "title": [
        "华为",
        "小米"
      ]
    }
  }
}

#范围搜索
GET adinfo/top/_search
{
  "query": {
    "range": {
      "sort_no": {
        "gte": 1,
        "lte": 20
      }
    }
  }
}

#过滤搜索:存在某个域
GET adinfo/top/_search
{
  "query": {
    "exists": {
      "field": "cat" 
    }
  }
}

#组合查询
GET adinfo/top/_search
{
  "query": {
   "bool": {
     "must": [
       {
         "term": {
           "cat": {
             "value": "手机"
           }
         }
       },
       {
         "range": {
           "sort_no": {
             "gt": 100,
             "lte": 200
           }
         }
       }
     ]
   }
  }
}

#字符查询，这个根据分词器来查询
GET adinfo/top/_search
{
  "query": {
    "match": {
      "title": "旗舰"
    }
  }
}

#前缀查询
GET adinfo/top/_search
{
  "query": {
    "prefix": {
      "title": {
        "value": "华为"
      }
    }
  }
}

#多个域匹配
GET adinfo/top/_search
{
  "query": {
   "multi_match": {
     "query": "手机",
     "fields": [
       "cat",
       "title"
       ]
   }
  }
}
```



### 5.5 ES升级7.9.1

因为新版本变化包括api都比较大，所以这里还是升级一下镜像：

```sh
#docker镜像下载
docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.1

#创建容器，其中9200是es与外部的通信端口，9300则是集群通信端口
docker run -id --name=z-es -p 9200:9200 -p 9300:9300 elasticsearch:7.9.1

#设置开机自启
docker update --restart=always z-es
```



---------------



同样的，下载IK分词器：

https://github.com/medcl/elasticsearch-analysis-ik/releases



```shell
#下载后上传到服务器解压
unzip elasticsearch-analysis-ik-7.9.1.zip -d ik-7.9.1

#将文件复制到容器里面
docker cp ./ik-7.9.1 z-es:/usr/share/elasticsearch/plugins

#重启容器
docker restart z-es
```

测试：

http://192.168.190.200:9200/_analyze?analyzer=ik_smart&pretty=true&text=狮子吃羚羊



------

安装kibana：

```shell
#拉镜像
docker pull docker.elastic.co/kibana/kibana:7.9.1

#创建容器 -e配置环境变量
docker run -itd -e ELASTICSEARCH_URL=http://192.168.190.200:9200 --name z-kibana --restart=always -p 5601:5601 kibana:7.9.1
```



## 6 微服务网关

微服务网关主要用于：

- 整合功能，前端页面直接访问服务需要对接的域名很多（路由），涉及跨域、服务端口暴露的安全问题。
- 日志统一记录
- 用户操作跟踪
- 限流操作
- 用户权限认证操作：需要统一的认证



实现微服务网关的技术：

- nginx
- zuul:netflix
- spring-cloud-gateway



### 6.1 搭建服务

#### 6.1.1 网关父工程

shop-gateway:

```xml
    <parent>
        <artifactId>shop-code-demo</artifactId>
        <groupId>com.zr</groupId>
        <version>1.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>shop-gateway</artifactId>
    <packaging>pom</packaging>

    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-gateway</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
        </dependency>
    </dependencies>

</project>
```



#### 6.1.2 指定微服务网关

一套架构可能有多个微服务网关：用户微服务网关、系统微服务网关

shop-gateway-web:

```xml

```



application.yml

```yaml
spring:
  application:
    name: shop-gateway-web
  cloud:
    gateway:
      globalcors:
        cors-configurations:
          '[/**]': # 匹配所有请求
            allowedOrigins: "*" #跨域处理 允许所有的域
            allowedMethods: # 支持的方法
              - GET
              - POST
              - PUT
              - DELETE
      routes:
        #商品微服务
        - id: shop_product_route
          uri: lb://product
          predicates: #请求的地址
            - Path=/product-server/**
          filters:
            - StripPrefix=1
            - name: Hystrix
                args:
                  name: default
                  fallbackUri: 'forward:/defaultfallback'
  redis:
    host: 192.168.190.200
    port: 6379
server:
  port: 9000

# hystrix 信号量隔离，3秒后自动超时
hystrix:
  command:
    default:
      execution:
        isolation:
          strategy: SEMAPHORE
          thread:
            timeoutInMilliseconds: 3000
  shareSecurityContext: true

eureka:
  client:
    service-url:
      defaultZone: http://test:123456@127.0.0.1:8000/eureka/
  instance:
    prefer-ip-address: true


management:
  endpoint:
    gateway:
      enabled: true
    web:
      exposure:
        include: true
```



### 6.2 网关过滤配置

路由过滤器允许用某种方式修改传入、传出的HTTP响应。

过滤器有20个实现类，包括头部过滤器、路径类过滤器、Hystrix过滤器以及变更请求URL过滤器、参数和状态码过滤器。

Spring Cloud Gateway包含了很多内置的GatewayFilter工厂，请求到不同的微服务上去。



#### 6.2.1 Host过滤

```yaml
      routes:
        #商品微服务
        - id: kkk
          uri: http://localhost:8001
          predicates: #请求的地址
            - Host=/baidu**
```

- id：表示唯一标识
- uri：指定路由的位置
- predicates：路由断言、路由的规则配置



测试：localhost:9000/



#### 6.2.2 路径匹配过滤

```yaml
      routes:
        #商品微服务
        - id: shop_product_route
          uri: lb://product-service
          predicates: #请求的地址
            - Path=/product-service/**
          filters:
            - StripPrefix=1
            - name: Hystrix
              args:
                name: default
                fallbackUri: 'forward:/defaultfallback'
```

测试：http://localhost:9000/product-service/shopsku/list

网关识别Path的路径，在`product-service`服务里面请求`/shopsku/list`接口



其中`StripPrefix=1`表示会去掉第一层前缀

如果需要默认加前缀：

```yaml
      routes:
        #商品微服务
        - id: shop_product_route
          uri: http://localhost:8080
          predicates: #请求的地址
            - Path=/product-service/**
          filters:
            - PrefixPath=/api
```

也就是会在每个请求前加上`/api`再到制定`localhost:8080`里面进行访问



#### 6.2.3 负载均衡

```yaml
      routes:
        #商品微服务
        - id: shop_product_route
          #实现负载均衡，主要应用于集群环境
          uri: lb://product-service
          predicates: #请求的地址
            - Path=/product-service/**
          filters:
            - StripPrefix=1
            - name: Hystrix
              args:
                name: default
                fallbackUri: 'forward:/defaultfallback'
```



### 6.3 网关限流

与nginx不同在于，gateway网关限流主要用于限制对每个微服务的访问次数，达到保护的目的。



#### 6.3.1 令牌桶算法

- 所有的请求在处理前都需要拿到一个可用的令牌。

- 根据限流大小，按照一定的速率往桶里面添加令牌。
- 桶设置的最大的放置令牌限制，当桶满了，新添加的令牌就被丢弃或者拒绝
- 请求达到首先获取桶中的令牌，之后才能进行其他业务逻辑，处理完成之后，把令牌删除
- 令牌桶有最低的限额，当桶中的令牌达到最低限额，请求处理完成后不会删除令牌，从而保证足够的限流

<img src="./images/令牌桶.png" style="zoom:67%;" />



#### 6.3.2 使用令牌桶进行请求次数限流

spring cloud gateway默认使用redis的RateLimter限流算法来实现。



1. **redis依赖**：

```xml
<!--redis-->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
            <version>2.1.3.RELEASE</version>
        </dependency>
```



2. **KeyResolver**:

用于计算某一个类型的限流的Key

这里使用IP进行限制，

```java
@SpringBootApplication
@EnableEurekaClient
public class ShopGatewayApplication {
    public static void main(String[] args) {
        SpringApplication.run(ShopGatewayApplication.class, args);
    }

    @Bean(name = "ipKeyResolver")
    public KeyResolver ipKeyResolver(){
        return new KeyResolver() {
            @Override
            public Mono<String> resolve(ServerWebExchange exchange) {
                return Mono.just(exchange.getRequest().getRemoteAddress().getHostName());
            }
        };
    }
}
```



3. **加入配置**：

```yaml
      routes:
        #商品微服务
        - id: shop_product_route
          uri: lb://product-service
          predicates: #请求的地址
            - Path=/product-service/**
          filters:
            - StripPrefix=1
            - name: RequestRateLimiter #请求数限流，名字使用默认的factory
              args:
                key-resolver: "#{@ipKeyResolver}"
                #每s只允许一个请求
                redis-rate-limiter.replenishRate: 1
                #允许并发有4个请求
                redis-rate-limiter.burstCapacity: 4
```



同样需要加入redis配置：

```yaml
spring:
  redis:
    host: 127.0.0.1
    port: 6379
```



### 6.4 用户中心

#### 6.4.1 数据表

这里只做最简单的用户名密码：

```sql
DROP TABLE IF EXISTS `SHOP_USER`;
CREATE TABLE `SHOP_USER` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `USER_ID` varchar(64) NOT NULL COMMENT 'USER_ID',
  `USER_NAME` varchar(64) NOT NULL COMMENT '用户名',
  `PASSWORD` varchar(64) NOT NULL COMMENT '密码',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改时间（格式：yyyy-MM-dd HH:mm:ss）',
  
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `USER_ID_INDEX` (`USER_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='用户登录表';
```



#### 6.4.2 创建微服务

分别创建`shop-service-user-api`和`shop-service-user`项目





### 6.4 网关鉴权

用户使用网关访问微服务，之后网关调用用户中心的登录请求获取用户信息，之后对用户信息进行加密返回给用户一个令牌。

用户再次调用的时候，网关对令牌进行校验。



首先还是配置网关：

```yaml
          - id: shop_user_route
            uri: lb://user-service
            predicates:
              - Path=/user-service/**
            filters:
              - StripPrefix=1
```



#### 6.4.1 JWT

参考博客：https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html



JWT: Json Web Token  可以携带用户信息，从而实现服务器不用保存session数据变为无状态。

包含了：

- header:描述信息

  `{"typ":"JWT","alg":"HS256"}`，type指令牌类型，alg指签名算法，HS256指HMAC SHA256

  之后会把这个JSON对象使用Base64转为字符串

- payload: 有效数据

  `{"iss":"签发人issuer"}`

  之后使用Base64转为字符串，但是不会再里面放私密信息

- signature:签证信息

  指定密钥（只有服务器保存）对前面两部分签名，防止篡改。

  

这三个部分中间通过`.`分割，组成完整的字符串。

```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.
eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.
TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ
```



一般来说JWT放在Http请求头部 Authorization字段里面传递



几个特点：

- 由于服务器无状态，无法在过程中废除token
- JWT本身包含了认证信息，对于重要的权限需要再次认证



#### 6.4.2 JJWT签发与验证token

JJWT是一个提供端到端的JWT创建和验证的Java库。

官方文档：

https://github.com/jwtk/jjwt



pom引入依赖：

```xml
<dependency>
    <groupId>io.jsonwebtoken</groupId>
    <artifactId>jjwt</artifactId>
    <version>0.9.0</version>
</dependency>
```





```java
public class TestJWT {
    public static void main(String[] args) {
        Map<String, Object> header = new HashMap<>();
        header.put("type", "JWT");
        header.put("alg", "HS256");

        Map<String, Object> payload = new HashMap<>();
        payload.put("userId", "123");
        payload.put("exp", new Date().getTime() / 1000 + 1);

        //生成JWT token
        Key key = new SecretKeySpec("test-sec".getBytes(), SignatureAlgorithm.HS256.getJcaName());
        String compact = Jwts.builder().setHeader(header)
                .setPayload(JSONObject.toJSONString(payload))
                .signWith(SignatureAlgorithm.HS256, key)
                .compact();
        System.out.println(compact);

        //解析token
        Jws<Claims> claimsJws = Jwts.parser().setSigningKey(key).parseClaimsJws(compact);
        JwsHeader header1 = claimsJws.getHeader();
        Claims body = claimsJws.getBody();
        System.out.println(JSONObject.toJSONString(header1));
        System.out.println(JSONObject.toJSONString(body));
    }
}
```



#### 6.4.3 认证

在用户中心登录之后，会返回一个令牌信息，之后每次请求需要带上这个令牌信息。



##### 6.4.3.1 JWT工具类

```java
public class JWTUtil {
    //有效期
    public static final Long JWT_TTL = 60L * 60 * 1000; //一个小时
    //设置秘钥明文
    public static final String JWT_KEY = "test";

    /**
     * 生成加密后的秘钥 secretKey
     *
     * @return
     */
    private static Key generalKey() {
        return new SecretKeySpec(JWT_KEY.getBytes(), SignatureAlgorithm.HS256.getJcaName());
    }


    /**
     * 生成JWT令牌
     *
     * @param id      id
     * @param subject 主题
     * @param ttl     有效时间，单位 ms
     * @param claims  自定义参数
     * @return 返回JWT令牌
     */
    public static String createJWT(String id, String subject, Long ttl, Map<String, Object> claims) {
        if (ttl == null) ttl = JWT_TTL;
        long exp = System.currentTimeMillis() + ttl;
        Date expDate = new Date(exp);
        JwtBuilder builder = Jwts.builder().setId(id)
                .setSubject(subject)
                .setIssuedAt(new Date())
                .signWith(SignatureAlgorithm.HS256, generalKey())
                .setExpiration(expDate)
                .addClaims(claims);
        return builder.compact();
    }

    /**
     * 解析令牌
     */
    public static Claims parseJWT(String jwt) {
        return Jwts.parser()
                .setSigningKey(generalKey())
                .parseClaimsJws(jwt)
                .getBody();
    }

    public static void main(String[] args) {
        HashMap<String, Object> map = new HashMap<>();
        map.put("name", "jason");
        String jwt = createJWT("111", "AA", 22000L, map);
        System.out.println(JSONObject.toJSONString(parseJWT(jwt)));
    }
}
```



##### 6.4.3.2 认证过滤器

```java
@Component
public class AuthorizationFilter implements GlobalFilter, Ordered {
    //定义header的键
    private static final String AUTHORIZE_TOKEN = "Authorization";

    /**
     * 全局拦截
     *
     * @param exchange
     * @param chain
     * @return
     */
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ServerHttpRequest request = exchange.getRequest();
        ServerHttpResponse response = exchange.getResponse();

        //获取用户令牌信息
        //从header里面获取
        String token = request.getHeaders().getFirst(AUTHORIZE_TOKEN);
        //如果是在参数中
        if (StringUtils.isBlank(token)) token = request.getQueryParams().getFirst(AUTHORIZE_TOKEN);
        //如果是在Cookie中
        if (StringUtils.isBlank(token)) {
            HttpCookie httpCookie = request.getCookies().getFirst(AUTHORIZE_TOKEN);
            if (httpCookie != null) {
                token = httpCookie.getValue();
            }
        }

        //如果没有令牌则进行拦截
        if (StringUtils.isBlank(token)) {
            response.setStatusCode(HttpStatus.UNAUTHORIZED);
            //响应空数据
            return response.setComplete();
        }

        //检验令牌是否有效
        try {
            JWTUtil.parseJWT(token);
        } catch (Exception e) {
            //可能会出现过期等信息，也就是解析无效
            response.setStatusCode(HttpStatus.UNAUTHORIZED);
            //响应空数据
            return response.setComplete();
        }
        //对有效的令牌放行
        return chain.filter(exchange);
    }

    @Override
    public int getOrder() {
        return 0;
    }
}
```



#### 6.4.4 加密算法



##### 6.4.4.1 可逆加密算法

加密后可以反向解密得到原文

- 对称加密：加密解密使用同样的密钥：

   `AES、DES、3DES、Blowfish、IDEA、RC4、RC5、RC6、HS256 `

- 非对称加密：使用公钥与私钥

  在加解密的情况下使用公钥加密、私钥解密，如果使用私钥加密的信息，公钥和私钥都可以解密

  在签名的情况，使用私钥进行签名（支付宝返回订单信息加签）、

  `RSA、DSA（数字签名用）、ECC（移动设备用）、RS256 (采用SHA-256 的 RSA 签名) `



##### 6.4.4.2 不可逆加密算法

加密后不能反向解密，用于校验下载文件、保存用户敏感信息

散列算法、摘要算法

 `MD5、SHA、HMAC`



##### 6.4.4.3 Base64编码

使用64个字符来编码二进制流：

```java
//编码
String base64encodedString = 
    Base64.getEncoder().encodeToString("runoob?java8".getBytes("utf-8"));
//解码
byte[] base64decodedBytes = Base64.getDecoder().decode(base64encodedString);
```





## 7 Spring Security Oauth2

之前使用网关过滤器只是完成了JWT有效性校验的操作，没有加入对应的权限。



### 7.1 认证与授权

**基本概念**：

认证：身份信息是否合法



授权：资源访问权限



第三方登录：比如微信就是通过Oauth2来获取access_token之后访问资源（需要维护本地账号和微信返回特殊id的信息）



单点登录：（SSO: single sign on）一个系统登录后，在受信任的其他系统都可以访问。通常就是把认证系统单独抽取出来，并且把用户信息保存在redis中，每次访问服务的时候，会先在认证系统里面进行认证。

<img src="./images/单点登录.png" style="zoom:80%;" />

相关认证框架：

- shiro

- cas
- spring security cas







### 7.2 Oauth2认证



#### 7.2.1 基本概念

相关博客：https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html

Oauth2是一个开放标准，允许用户授权第三方应用（社区网站）访问他们在其他服务提供者（比如微信认证）的信息，而不用将用户名和密码提供给第三方应用（比如在社区网站使用微信认证那登录是在微信的平台，而不用在社区使用账号密码登录，当然也有密码模式来登录的但仅仅在用户对客户端高度信任的情况下）。



微信认证：

https://developers.weixin.qq.com/doc/oplatform/Website_App/WeChat_Login/Wechat_Login.html

<img src="./images/微信认证.png" style="zoom:97%;" />



#### 7.2.1 Oauth2在项目中的应用

- 通过第三方认证登录（微信、QQ、微博）并获取资源（用户昵称、基本资料等，主要看提供的接口）
- 外部系统访问资源，也就是开放API，可以通过Oauth2访问
- 前后端交互接口，也就是正常的登录校验授权
- 微服务之间调用方法



<img src="./images/系统认证授权.png" style="zoom:80%;" />



### 7.3 搭建认证服务



## 8 订单



### 8.1 常见的问题

基础的查询用户对应地址列表、查询购物车这里就不实现了，直接使用接口模拟下单接口，

下单的同时需要把对应的数据从购物车删除。	



下单主要的几个问题：

1. 价格异常

2. 库存检查（超卖问题）



对于库存来说，多线程的请求无法保证原子性，出现超卖的现象。

可以使用数据库行级锁来操作，也就是`update table set num = xxx where num>=xxx`

但是每次都直接使用数据库CAS等待时间较长，而且可能会有多个请求等待并且失败，所以可以再引入redis缓存库存数据，总结下步骤就是：

1. 用户下单，查询redis中的库存信息（没有就从数据库更新库存记录），然后将值进行incr。
2. 到数据库使用乐观锁进行减库存。





这里又涉及到多个服务之前事务管理的问题，因为下单业务在订单中心，库存操作在产品中心（有的需要出货入货单的会单独有库存中心），所以必须引入分布式事务。



微信或者支付宝支付就是签名发送，异步回调，可以通过查询订单状态获取支付结果（一般还是使用异步回调）。这个时候异步回调需要提供外网的IP，如果使用的内网可以使用ngrok（https://ngrok.com/docs）来提供虚拟ip。（也就是内网穿透，还有花生壳也可以，它使用外部域名绑定内网地址，同时在本地对外服务器里面记录下域名对应的内网地址，这样外部每次请求的时候，就会先请求本地服务器，然后找到内网ip进行访问）

支付回调有时候会遇到多次回调的问题，这个时候需要对订单状态进行校验（当然，如果出现短时间多次回调那就是回调接口的返回数据不合法，支付宝最短10分钟内再次回调，微信15s，其实一般都能满足不会重复回调），为了再加一层保障不会因为大量支付导出回调接口阻塞，可以使用MQ来处理。



除了事务之外，还要考虑业务上的东西：

- 订单和支付系统分开的情况，涉及支付的时候，可以使用MQ来做支付回调状态的处理。支付宝或者微信回调支付服务里面的支付成功的接口，然后支付服务通过mq发送支付成功的消息，订单服务监听消息完成状态修改。

- 对于超时取消的订单，使用MQ延时队列来实现。





为了能够实际操作，这里使用支付宝沙箱环境来进行开发测试。



### 8.2 订单数据模型

#### 订单表

订单的表包含数据比较多，主要是订单支付情况、用户信息、物流信息及物流状态这三个数据。

订单表还可以添加的信息包括：

子订单数量、订单明细数量、开票信息。

```sql
DROP TABLE IF EXISTS `SHOP_ORDER`;
CREATE TABLE `SHOP_ORDER` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `ORDER_ID` varchar(64) NOT NULL COMMENT '订单 ID',
  `PRODUCT_FEE` int(11) NOT NULL DEFAULT '0' COMMENT '商品金额,单位：分',
  `POST_FEE` int(11) NOT NULL DEFAULT '0' COMMENT '邮费金额,单位：分',
  `PAY_AMOUNT` int(11) NOT NULL DEFAULT '0' COMMENT '实际支付金额,单位：分',
  `PAY_TYPE` tinyint(4) NOT NULL DEFAULT '0' COMMENT '支付类型 0 线上支付 1 货到付款',
  `PAY_STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '支付状态 0 未支付 1 已支付',
  `ORDER_STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '订单状态 0:挂起 1:已拆分 2:已关闭 3:交易完成 4:结单',
  `PAY_TIME` datetime DEFAULT NULL COMMENT '支付时间（格式：yyyy-MM-dd HH:mm:ss）',
  `POST_TIME` datetime DEFAULT NULL COMMENT '发货时间（格式：yyyy-MM-dd HH:mm:ss）',
  `FINISH_TIME` datetime DEFAULT NULL COMMENT '交易完成时间（格式：yyyy-MM-dd HH:mm:ss）',
  `CLOSE_TIME` datetime DEFAULT NULL COMMENT '交易关闭时间（格式：yyyy-MM-dd HH:mm:ss）',
  `BUYER_REMARK` varchar(1000) DEFAULT NULL COMMENT '买家留言',
  `CST_ID` varchar(64) DEFAULT NULL COMMENT '用户ID',
  `CST_NAME` varchar(64) DEFAULT NULL COMMENT '用户名称',
  `RECEIVER_NAME` varchar(50) DEFAULT NULL COMMENT '收货人名称',
  `RECEIVER_PHONE` varchar(12) DEFAULT NULL COMMENT '收货人手机',
  `RECEIVER_ADDR` varchar(200) DEFAULT NULL COMMENT '收货人地址',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建日期（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '最后修改人',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改日期（格式：yyyy-MM-dd HH:mm:ss）',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `ORDER_ID_INDEX` (`ORDER_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='商品订单表';
```



#### 子订单

子订单主要是作为关联库存厂家来使用，并且需要对订单进行拆单完成支付的商品和邮费的分摊（看具体业务），这里比订单表增加了物流信息，并保留了收货信息（为了方便后续更改，也就是用户可以在子订单维度再次修改收货地址）

这里还可以根据业务添加的信息：

收款方账号信息（比如B端就是收款部门、C端就是收款用户）、店铺信息、折扣优惠信息，看业务而定，一般子订单因为关联了店铺、库房，都是最为复杂的一张表。

```sql
DROP TABLE IF EXISTS `SHOP_SUB_ORDER`;
CREATE TABLE `SHOP_SUB_ORDER` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SUB_ORDER_ID` varchar(64) NOT NULL COMMENT '子订单 ID',
  `ORDER_ID` varchar(64) NOT NULL COMMENT '订单 ID',
  `STORE_ID` varchar(64) NOT NULL COMMENT '厂家（库房） ID',
  `PRODUCT_PART_FEE` int(11) NOT NULL DEFAULT '0' COMMENT '商品分摊金额,单位：分',
  `POST_PART_FEE` int(11) NOT NULL DEFAULT '0' COMMENT '邮费分摊金额,单位：分',
  `PAY_PART_AMOUNT` int(11) NOT NULL DEFAULT '0' COMMENT '实际收款金额,单位：分',
  `POST_TIME` datetime DEFAULT NULL COMMENT '发货时间（格式：yyyy-MM-dd HH:mm:ss）',
  `FINISH_TIME` datetime DEFAULT NULL COMMENT '交易完成时间（格式：yyyy-MM-dd HH:mm:ss）',
  `CLOSE_TIME` datetime DEFAULT NULL COMMENT '交易关闭时间（格式：yyyy-MM-dd HH:mm:ss）',
  `BUYER_REMARK` varchar(1000) DEFAULT NULL COMMENT '买家留言',
  `SHIPPING_NAME` varchar(20) DEFAULT NULL COMMENT '物流名称',
  `SHIPPING_CODE` varchar(20) DEFAULT NULL COMMENT '物流单号',
  `SHIPPING_STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '物流状态 0:未发货 1:已发货 2:已送达 3:异常',
  `SUB_ORDER_STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '订单状态: 1：待付款 2：待发货 3：已发货 4：已签收 5：确认收货 6：售后期 7：交易完成 8：关闭',
  `CST_ID` varchar(64) DEFAULT NULL COMMENT '用户ID',
  `CST_NAME` varchar(64) DEFAULT NULL COMMENT '用户名称',
  `RECEIVER_NAME` varchar(50) DEFAULT NULL COMMENT '收货人名称',
  `RECEIVER_PHONE` varchar(12) DEFAULT NULL COMMENT '收货人手机',
  `RECEIVER_ADDR` varchar(200) DEFAULT NULL COMMENT '收货人地址',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建日期（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '最后修改人',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改日期（格式：yyyy-MM-dd HH:mm:ss）',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SUB_ORDER_ID_INDEX` (`SUB_ORDER_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='商品子订单表';
```



#### 订单明细表

这里减少了很多内容，主要就是和sku绑定以及保存金额，

实际上还应该尽可能的把一些附带信息保存到表里面避免多次查询：

比如商品名牌信息、产品分类信息、店铺名称、以及sku的一些信息（条码、型号、基本描述）

```sql
DROP TABLE IF EXISTS `SHOP_ORDER_ITEM`;
CREATE TABLE `SHOP_ORDER_ITEM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `ORDER_ITEM_ID` varchar(64) NOT NULL COMMENT '订单明细 ID',
  `ORDER_ID` varchar(64) NOT NULL COMMENT '订单 ID',
  `SUB_ORDER_ID` varchar(64) NOT NULL COMMENT '子订单 ID',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU ID',
  `NUM` int(10) NOT NULL COMMENT '购买数量',
  `PRICE` int(9) NOT NULL DEFAULT '0' COMMENT '单价,单位：分',
  `PRODUCT_FEE` int(11) NOT NULL DEFAULT '0' COMMENT '总金额,单位：分',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建日期（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '最后修改人',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改日期（格式：yyyy-MM-dd HH:mm:ss）',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `ORDER_ITEM_ID_INDEX` (`ORDER_ITEM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='订单明细表';
```



### 8.3 提交订单

下单业务：



支付系统回调后进入mq，订单中心通过mq监听器修改订单状态：

首先在控制台创建exchange、queue，这里服务单一目的明确，直接使用单向的（direct）exchange就可以了

localhost:15672



