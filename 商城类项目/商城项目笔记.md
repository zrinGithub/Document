# 商城项目笔记

[TOC]



## 1.项目搭建

### 1.1虚拟机

软件使用`VMware® Workstation 15 Pro`，版本`15.5.1 build-15018445`

镜像使用`CentOS-7-x86_64-Minimal-1908.iso`（docker安装需要）

因为之前的笔记比较散，所以这里尽量做最全面的部署说明：



#### 1.1.1安装

这个镜像就是最小镜像，所以没有图形化界面：

进入界面，选择`Install CentOs7`之后随便选。

设定root密码123456



##### 1.1.1.1上传下载文件

`yum -y install lrzsz `

#### 1.1.2网络配置

##### 1.1.2.1网关与ip

首先需要查看当前虚拟机网关的地址，具体位置：

`控制面板\网络和 Internet\网络连接`

查看VMnet8的网关地址



也可以直接在管理员模式下启动Vmware，然后点击菜单->编辑->虚拟网络编辑器里面查看

```shell
编辑
vim /etc/sysconfig/network-scripts/ifcfg-ens33 

内容
......
BOOTPROTO=static
NAME=ens33
DEVICE=ens33
ONBOOT=yes
IPADDR=192.168.190.200
NETMASK=255.255.255.0
GATEWAY=这里就是网关地址
DNS1=8.8.8.8

重启
service network restart
```



如果是复制的机器，建议在开启的时候直接选择移动的机器，然后修改ip地址即可，如果选择复制，可能需要设计网卡的修改。



##### 1.1.2.2关闭防火墙

因为后面需要开放端口，这里我们直接关闭防火墙

```shell
#查看防火墙状态
firewall-cmd --state

#停止firewall
systemctl stop firewalld.service

#禁止firewall开机自启
systemctl disable firewalld.service
```



#### 1.1.3Docker安装

参考官网：https://docs.docker.com/install/linux/docker-ce/centos/

安装需要CentOs7主版本

docker包含 EE企业版本和CE社区版本。



官网关于stable/nightly/test三个更新渠道的说明

> - **Stable** gives you latest releases for general availability.
> - **Test** gives pre-releases that are ready for testing before general availability.
> - **Nightly** gives you latest builds of work in progress for the next major release.





##### 1.1.3.1使用Docker Repository来安装

官网推荐设置Docker repository来安装：



- 删除旧版本

```shell
$ sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```



- 安装`yum-utils`包（提供`yum-config-manager`功能）并设定稳定的仓库

```shell
$ sudo yum install -y yum-utils

$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
```



- 官方建议安装nightly或者test更新渠道

```shell
开启nightly repository
$ sudo yum-config-manager --enable docker-ce-nightly

启动test
$ sudo yum-config-manager --enable docker-ce-test

关闭nightly或者test使用--disable即可
$ sudo yum-config-manager --disable docker-ce-nightly
```



- 安装特定版本

```shell
查看版本列表
$ sudo yum list docker-ce --showduplicates | sort -r

docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable
docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable
docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable
docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable

安装时候使用docker-ce加上版本号，如docker-ce-18.06.0.ce('-'前面为版本号)
$ sudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io
```



- 安装最新版本

```shell
$ sudo yum install docker-ce docker-ce-cli containerd.io
```



- 启动

```shell
$ sudo systemctl start docker
```



- 测试

```shell
$ sudo docker run hello-world
```



##### 1.1.3.2使用安装包

- 下载版本 https://download.docker.com/linux/centos/7/x86_64/ 选择安装版本
- 安装：`yum install /path/to/package.rpm`
- 启动：`systemctl start docker`
- 测试：`docker run hello-world`



##### 1.1.3.3使用阿里docker社区版yum源安装

```shell
 # 安装wget
 yum install wget
 
 # 下载阿里云docker社区版yum源
 cd /etc/yum.repos.d/
 wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
 
 # 查看docker安装包
 yum list | grep docker
 
 # 安装docker ce社区版本
 yum install -y docker-ce.x86_64
 
 # 设置开机启动
 systemctl enable docker
 
 # 更新xfsprogs
 yum -y update xfsprogs
 
 # 启动docker
 systemctl start docker

 # 查看版本
 docker version
 
 # 查看详细信息
 docker info
```



#### 1.1.4设置Docker容器自动启动

```shell
docker update --restart=always CONTAINER_NAME/CONTAINER_ID
```



#### 1.1.5 docker安装mysql

```shell
# 查看可用版本
docker search mysql

# 拉取官方镜像
docker pull mysql:5.7

#运行，-p前面是宿主机地址，后面是容器地址
docker run -itd --name z-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7

#设定开机自启
docker update --restart=always z-mysql

#进入容器
docker exec -it z-mysql /bin/bash
```





#### 1.1.5 docker安装redis

https://hub.docker.com/_/redis/



因为涉及远程连接，需要挂载外部文件

```shell
mkdir -p /root/docker/redis/conf

#这里我直接找官网http://download.redis.io/releases/的redis.conf文件到/root/docker/redis/conf目录下
#这里配置密码，可以吧protected-mode打开
vim /root/docker/redis/conf/redis.conf
#取消访问地址限制
#bind 127.0.0.1 
#设置访问密码，redis需要认证使用命令： auth myPassword
#或者在连接的时候./redis-cli -h 192.168.190.200 -p 6379 -a 123456
protected-mode no
requirepass 123456  
```



镜像：

```shell
# 查看可用版本
docker search redis

# 拉取官方镜像
docker pull redis

#运行，-p前面是宿主机地址，后面是容器地址
docker run -itd --name z-redis -p 6379:6379 \
-v /root/docker/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
redis redis-server /usr/local/etc/redis/redis.conf

#设定开机自启
docker update --restart=always z-redis

#进入容器
docker exec -it z-redis /bin/bash
```



### 1.3基础代码结构

#### 1.3.1父工程

父工程主要负责导入springboot、springcloud



> parent标签主要用于实现复用父类的依赖以及统一管理依赖的版本号。





### 1.4服务地址与端口

#### 1.4.1项目服务

| 服务          | 说明           | 端口 |
| ------------- | -------------- | ---- |
| eureka-server | eureka注册中心 | 8000 |
| fastdfs-ops   | fastdfs操作    | 8001 |
|               |                |      |



#### 1.4.2服务配置

均使用一台虚拟机安装，所以地址都在`192.168.190.200`

| 服务            | 端口                | 相关配置文件                                                 |
| --------------- | ------------------- | ------------------------------------------------------------ |
| fastdfs tracker | 22122 nginx端口8080 | nginx配置文件：/etc/nginx/conf/nginx.conf<br />tracker配置文件：/etc/fdfs/tracker.conf |
| fastdfs storage | 23000 nginx端口8080 | nginx配置文件：/etc/nginx/conf/nginx.conf<br />storage配置文件：/etc/fdfs/storage.conf<br />存储位置：/data/fast_data |
| redis           | 6379                |                                                              |
| mysql           | 3306                |                                                              |
| openresty nginx | 80                  | /usr/local/openresty/nginx/                                  |



### 1.5 Jmeter

Jmeter可以用于负载和性能测试。

官网：https://jmeter.apache.org/



#### 1.5.1 JMeter安装

本地先要有jdk环境，这里本地的jdk是1.8。



JMeter下载地址 ： https://jmeter.apache.org/download_jmeter.cgi

解压后点击bin路径下的jmeter.bat即可



## 2. fastDfs

fastDfs是开源的轻量级分布式文件系统，包含tracker server、storage server。

tracker负责复杂均衡和调度，上传的时候寻找可用的storage来存储。

<img src="./images/fastdfs上传.png" style="zoom:67%;" />





### 2.1Docker安装fastDfs

- 拉取镜像：

  ```shell
  docker pull morunchang/fastdfs
  
  #因为拉取太慢了，我也不知道能不能拉下来，所以从其他虚拟机拷贝的
  #保存压缩镜像到本地
  docker save a729ac95698a | gzip > fastdfs.tar.gz
  #发送到安装机器
  scp fastdfs.tar.gz root@192.168.190.200:/root
  #解压并加载到本地仓库
  gunzip -c fastdfs.tar.gz | docker load
  #重命名
  docker tag a729ac95698a morunchang/fastdfs
  ```

  

- 运行tracker：

  ```shell
  docker run -d --name tracker --net=host morunchang/fastdfs sh tracker.sh
  --net:使用的网路模式为host，也就是共享主机network namespace可以直接访问主机的网络信息，缺点是两个容器的端口必须不同，因为都是使用主机的接口。
  ```

  

- 运行storage：

  ```shell
docker run -d --name storage --net=host -e TRACKER_IP=<your tracker server address>:22122 -e GROUP_NAME=<group name> morunchang/fastdfs sh storage.sh
  
  --net:使用的网路模式为host，也就是共享主机network namespace可以直接访问主机的网络信息，缺点是两个容器的端口必须不同，因为都是使用主机的接口。
  -e添加到环境变量
  	TRACKER_IP  track机器的ip
  	GROUP_NAME	组名，也就是storage的组，新的storage服务器组名需要改变
  
  
  #本例使用
  docker run -d --name storage --net=host -e TRACKER_IP=192.168.190.200:22122 -e GROUP_NAME=group1 morunchang/fastdfs sh storage.sh
  ```
  
  
  
- storage内部修改nginx配置

  ```shell
  #进入容器
  docker exec -it storage /bin/bash
  #修改nginx配置
  vim /etc/nginx/conf/nginx.conf
  
  #里面已经有配置了，nginx端口8080
  location ~ /M00 {
  	root /data/fast_data/data;
      ngx_fastdfs_module;
  }
  #如果不希望浏览器缓存的话（比如删除希望立即删除）
  add_header Cache-Control no-store;
  
  #退出容器
  exit
  
  #重启storage容器
  docker restart storage
  ```



- 查看启动的容器：`docker ps`

- 开机启动设置：

  ```shell
  docker update --restart=always tracker
  docker update --restart=always storage
  ```

- 查看配置文件

  ```shell
  docker exec -it storage /bin/bash
  cd /etc/fdfs/
  vim storage.conf
  #里面的store_path0表示文件的位置
  store_path0=/data/fast_data
  #tracker的地址
  tracker_server=192.168.211.132:22122
  ```

  

### 2.2fastDfs服务代码

#### 2.2.1安装依赖

看了几个不同的项目，基本都是使用github上面的这个项目： https://github.com/happyfish100/fastdfs-client-java

文档里面写得很清楚了，使用idea的话install一下就可以了。

安装到本地库之后使用pom导入（注意版本号和安装的一样）：

```xml
        <dependency>
            <groupId>org.csource</groupId>
            <artifactId>fastdfs-client-java</artifactId>
            <version>1.29-SNAPSHOT</version>
        </dependency>
```



#### 2.2.2配置文件

`application.yml`

```yaml
spring:
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
  application:
    name: fastdfs-ops
server:
  port: 8001
eureka:
  client:
    service-url:
      defaultZone: http://test:123456@127.0.0.1:8000/eureka/
  instance:
    prefer-ip-address: true
feign:
  hystrix:
    enabled: true
```



`fdfs_client.conf`

```properties
connect_timeout = 60
network_timeout = 60
charset = UTF-8
http.tracker_http_port = 8080
tracker_server = 192.168.190.200:22122
```



启动类：

```java
@SpringBootApplication
@EnableEurekaClient
@EnableSwagger2
public class FastDFSApplication {
    public static void main(String[] args) {
        SpringApplication.run(FastDFSApplication.class, args);
    }
}
```



#### 2.2.3文件上传下载实现

包装类：

```java
@Data
@Accessors(chain = true)
public class FastDFSFile {
    //文件名字
    private String name;
    //文件内容
    private byte[] content;
    //文件扩展名
    private String ext;
    //文件创建作者
    private String author;
}
```



-----



Client代码：

```java
@Component
@Slf4j
public class FastDFSClient {
    private TrackerServer trackerServer;
    private TrackerClient trackerClient;
    private StorageServer storageServer;
    //使用StorageClient1而不是StorageClient只是为了方便操作组名和文件路径（想一下你不用自己去加分隔符了）
    private StorageClient1 storageClient;

    //设定默认的配置，可以在application.yml里面修改
    @Value("${fastdfs.http.permit.types:png,jpg,jpeg,doc,xls,pdf,bmp,gif}")
    private String permitTypes;
    private String[] types;
    //这里的前缀就是服务位置+端口号
    private String prefix;

    @PostConstruct
    public void init() throws Exception {
        String path = new ClassPathResource("fdfs_client.conf").getFile().getAbsolutePath();
        ClientGlobal.init(path);
        trackerClient = new TrackerClient();
        trackerServer = trackerClient.getTrackerServer();
        storageServer = null;
        storageClient = new StorageClient1(trackerServer, storageServer);
        types = permitTypes.split(",");
        prefix = "http://" + trackerServer.getInetSocketAddress().getHostString()
                + ":" + ClientGlobal.getG_tracker_http_port() + "/";
    }

    /**
     * 上传输入流
     *
     * @param file 包装的文件数据
     * @return 文件路径
     */
    public String uploadFile(FastDFSFile file) throws Exception {
        //1.判定文件类型是否合法
        boolean permit = false;
        for (String type : types) {
            if (type.equals(file.getExt())) {
                permit = true;
                break;
            }
        }

        if (!permit) {
            String errMsg = "上传文件格式不允许";
            log.error(errMsg);
            throw new Exception(errMsg);
        }
        //2.封装参数
        NameValuePair[] metas = new NameValuePair[2];
        metas[0] = new NameValuePair("name", file.getName());
        metas[1] = new NameValuePair("author", file.getAuthor());
        //3.上传文件
        String relativePath = storageClient.upload_file1(file.getContent(), file.getExt(), metas);
        return prefix + relativePath;
    }

    /**
     * 删除文件
     *
     * @param filePath 文件路径
     * @return 返回操作结果判定
     * @throws IOException
     * @throws MyException
     */
    public boolean deleteFile(String filePath) throws IOException, MyException {
        return 0 == storageClient.delete_file1(StringUtils.replace(filePath, prefix, ""));
    }

    /**
     * 获取下载文件流
     *
     * @param filePath 文件完整路径
     * @return 返回输入流
     * @throws IOException
     * @throws MyException
     */
    public InputStream downloadFileStream(String filePath) throws IOException, MyException {
        byte[] content = storageClient.download_file1(filePath);
        return new ByteArrayInputStream(content);
    }

    /**
     * 获取下载文件Base64编码
     *
     * @param filePath 文件完整路径
     * @return 返回BASE64编码
     * @throws IOException
     * @throws MyException
     */
    public String downloadFileBase64(String filePath) throws IOException, MyException {
        try (InputStream inputStream = downloadFileStream(filePath)) {
            byte[] bytes = IOUtils.toByteArray(inputStream);
            String fileType = StringUtils.substringAfterLast(filePath, ".");
            String encodeStr = Base64.getEncoder().encodeToString(bytes);
            return String.format("data:image/%s;base64,", fileType) + encodeStr;
        } catch (Exception e) {
            return null;
        }
    }
}

```



-----



Controller代码：

```java
@RestController
@RequestMapping("fastdfs")
@Slf4j
public class FastDFSController {
    @Resource
    private FastDFSClient client;

    @PostMapping("upload")
    public RespVo<String> upload(MultipartFile file) {
        if (file == null) {
            return new RespVo<>(false, null, "文件不存在");
        }

        String filename = file.getOriginalFilename();
        if (StringUtils.isEmpty(filename)) {
            return new RespVo<>(false, null, "文件不存在");
        }

        try {
            String ext = filename.substring(filename.lastIndexOf(".") + 1);
            //TODO: 这里结合后面的权限校验把申请用户填进去
            FastDFSFile dfsFile = new FastDFSFile().setContent(file.getBytes()).setExt(ext).setName(filename).setAuthor("root");
            String fileDfsPath = client.uploadFile(dfsFile);
            return new RespVo<>(true, fileDfsPath, "文件上传成功");
        } catch (Exception e) {
            log.error("文件上传失败", e);
            return new RespVo<>(false, null, "文件上传失败");
        }
    }

    @GetMapping("delete")
    public RespVo<String> delete(@RequestParam("filePath") String filePath) throws IOException, MyException {
        if (client.deleteFile(filePath))
            return new RespVo<>(true, null, "文件删除成功");
        return new RespVo<>(false, null, "文件删除失败");
    }
}
```





#### 2.2.4 测试

验证文件：

```shell
#进入容器
docker exec -it storage /bin/bash

cd /etc/fdfs/
```





## 3.商品模型

根据业务不同，产商品模型的关联关系不同，这里采用B2C的模式构建产商品模型：



### 3.1SPU

SPU: Standard Product Unit 标准产品单位，一般理解为一款商品。



这里使用的类目字段表示第三级类目，有的需求里面可以在任意类目下创建产品，也就是这里的`CATEGORY_ID`不一定是三级类别。

为了快速进行单表查询，一般不仅仅展示最后一级类目，会把三级的类别都作为字段存储。

```mysql
CREATE TABLE `SHOP_SPU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SPU_ID` varchar(64) DEFAULT NULL COMMENT 'SPU ID',
  `SPU_NAME` varchar(64) DEFAULT NULL COMMENT '名称',
  `TITLE` varchar(64) DEFAULT NULL COMMENT '标题',
  `SPU_PIC_URL` varchar(2000) DEFAULT NULL COMMENT '图片地址',
  `DESCRIPTION` varchar(512) DEFAULT NULL COMMENT '描述',
  `CATEGORY_ID` varchar(36) NOT NULL COMMENT '三级类别ID',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '上下架状态，0新建，1已下架，2已上架',
  `IS_HOT` tinyint(1) NOT NULL DEFAULT '0' COMMENT '是否是热销产品，0否，1是',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `LIST_TIME` datetime DEFAULT NULL COMMENT '上架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELIST_TIME` datetime DEFAULT NULL COMMENT '下架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PRODUCT_ID_INDEX` (`SPU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SPU产品数据';
```



### 3.2SKU

SKU: Stock Keeping Unit 库存单位，通过SPU指定规格参数生产，一般理解为最小销售/库存单位。



一般为了快速进行单表查询，也会把类别、品牌、评价数的字段加到表里面

```mysql
CREATE TABLE `SHOP_SKU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU ID',
  `SPU_ID` varchar(64) NOT NULL COMMENT '关联SPU ID',
  `PRICE` int(9) NOT NULL DEFAULT '0' COMMENT '价格,单位：分',
  `QUANTITY` int(4) DEFAULT NULL COMMENT '库存数量',
  `SKU_PIC_URL` varchar(256) DEFAULT NULL COMMENT '图片地址',
  `STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '上下架状态，0新建，1已下架，2已上架',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建日期（格式：yyyy-MM-dd HH:mm:ss）',
  `LIST_TIME` datetime DEFAULT NULL COMMENT '上架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELIST_TIME` datetime DEFAULT NULL COMMENT '下架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改日期（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT 'sku最后修改人',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SKU_ID_INDEX` (`SKU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU商品表';
```



### 3.3类别、参数与自定义参数

**类别表：**

```mysql
CREATE TABLE `SHOP_CATEGORY` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(36) NOT NULL COMMENT '类别ID',
  `CATEGORY_NAME` varchar(128) NOT NULL COMMENT '类别名称',
  `CATEGORY_LEVEL` tinyint(2) NOT NULL DEFAULT '0' COMMENT '类别等级',
  `PARENT_ID` varchar(36) DEFAULT NULL COMMENT '父ID（一级分类的 PARENT_ID = 0）',
  `SORT` int(11) DEFAULT NULL COMMENT '排序',
  `REMARK` varchar(512) DEFAULT NULL COMMENT '备注',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `CATEGORY_STATUS` tinyint(1) NOT NULL DEFAULT '1' COMMENT '状态，0禁用，1启用',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `CATEGORY_ID_INDEX` (`CATEGORY_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别表';
```



-----



**参数表：**

```mysql
CREATE TABLE `SHOP_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `PARAM_ID` varchar(64) NOT NULL COMMENT '参数ID',
  `PARAM_TYPE` tinyint(1) NOT NULL COMMENT '类型（0规格属性，1其他属性）',
  `PARAM_NAME` varchar(64) NOT NULL COMMENT '名称',
  
  `ORDER_NUM` int(11) DEFAULT '0' COMMENT '排序',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`PARAM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='参数表';
```

对应下面这张图来看：`PARAM_TYPE`这个字段主要还是区分**规格参数**和sku之间有差别的参数（其他参数）。

**规格参数**是指能够区分出sku的参数。具体来说，产品关联了类别id，找到对应的规格参数，通过勾选规格参数的笛卡尔积生成SKU。

**其他参数**在很多业务上是不需要的，因为大多数时间产商品都是同一类，如下图像库存数量、重量都是必填项，属于SKU表中的固定字段，但是如果我们的商城还存在没有重量、库存这种指标的商品（比如视频、游戏账号），那么可以把这些参数作为其他参数。

<img src="./images/规格参数与sku.png" style="zoom: 50%;" />



**参数类别关联：**我们需要把规格参数和类别关联起来，这里见仁见智根据业务决定是只能在三级类别上面挂载参数还是任意级别。

```mysql
CREATE TABLE `SHOP_SPU_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SPU_ID` varchar(64) NOT NULL COMMENT 'SPU_ID',
  `PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`SPU_ID`,`PARAM_ID`)
) ENGINE=InnoDB AUTO_INCREMENT=102 DEFAULT CHARSET=utf8 COMMENT='SPU-参数关联';
```

这里参数是关联的类别，我们后面使用SPU关联类别来找到参数。

根据需求有时候可能会在SPU这个级别重新制定参数，也就是类别的参数可能只是作为一个选择，那么我们只选定SPU需要的参数，这个时候需要再有一个关联SPU和参数的表。



----



**自定义参数表：**

**自定义参数**作为sku规格以外的*补充参数*（比如生产厂商、物流仓库地址等不影响价格的因素，当然最重要的是不影响sku库存最小单位）。

这个表设计和参数表一样，需要挂载到类别上面，作为SPU级别的补充参数。



**SKU参数值关联：**

以前很多项目喜欢使用json的格式来保存像规格参数这种数据，实际上为了快速进行单表查询，可以把这种字段作为冗余保存在sku的表中，但是为了方便对参数进行定义和CRUD，最好还是把这些数据作为单独的表分割出来。

所以我们可以通过SKU_ID关联到属性值：

```mysql
CREATE TABLE `SHOP_SKU_PARAM_VALUE` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU的ID',
  `PARAM_VALUE_ID` varchar(64) NOT NULL COMMENT '参数值ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SKU_PARAM_VALUE_ID_UKEY` (`SKU_ID`,`PARAM_VALUE_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU - 参数值表';
```



**参数值：**

```mysql
CREATE TABLE `SHOP_PARAM_VALUE` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `PARAM_VALUE_ID` varchar(64) NOT NULL COMMENT 'PARAM_VALUE_ID',
  `PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  `PARAM_VALUE` varchar(256) NOT NULL COMMENT '产品属性值',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_VALUE_ID_INDEX` (`PARAM_VALUE_ID`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=896 DEFAULT CHARSET=utf8 COMMENT='参数值表';
```





## 4.缓存实现-首页广告位示例

### 4.1基本思路

首页的内容对响应速度敏感，所以我们需要使用缓存存储首页广告位。

<img src="./images/广告缓存方案.png" style="zoom:67%;" />



### 4.2表结构

```mysql
CREATE TABLE `SHOP_AD_CONTENT` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `AD_ID` varchar(64) NOT NULL COMMENT '广告ID',
  `AD_CATEGORY_ID` varchar(64) NOT NULL COMMENT '广告类目ID',
  `AD_TITLE` varchar(256) NOT NULL COMMENT '标题',
  `AD_URL` varchar(256) DEFAULT NULL COMMENT '连接地址',
  `AD_PIC_URL` varchar(256) DEFAULT NULL COMMENT '图片地址',
  `AD_STATUS` tinyint(1) NOT NULL DEFAULT '1' COMMENT '状态，0禁用，1启用',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `AD_ID_INDEX` (`AD_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='广告表';

CREATE TABLE `SHOP_AD_CATEGORY` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `AD_CATEGORY_ID` varchar(64) NOT NULL COMMENT '广告类目ID',
  `AD_CATEGORY_NAME` varchar(256) NOT NULL COMMENT '广告类目名称',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `AD_CATEGORY_ID_INDEX` (`AD_CATEGORY_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='广告类目表';
```



### 4.2 Lua脚本语言

轻量脚本语言，c编写主要是为了提供扩展定制功能（脚本的另外一种说法）。

参考学习： https://www.runoob.com/lua/lua-tutorial.html 

特点：

- 支持面向过程 (Procedure Oriented)和函数式编程(Functional Programming)  
- 仅使用通用类型的表
- 闭包



**安装**

```shell
#相关依赖库安装
yum install ‐y gcc
yum install libtermcap‐devel ncurses‐devel libevent‐devel readline‐devel

#获取包并解压
curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz
tar xzvf lua-5.3.0.tar.gz 

#安装
cd lua-5.3.0
make linux test
make install

#测试
lua
```



**执行**

可以使用文件执行：

```shell
vim hello.lua
#内容
print("hello world")

#执行
lua hello.lua
```



也可以直接`lua`命令进入控制台写



**注释**

```lua
--这是单行注释
--[[
这是多行注释
--]]
```



**关键字**

|          |       |       |        |
| -------- | ----- | ----- | ------ |
| and      | break | do    | else   |
| elseif   | end   | false | for    |
| function | if    | in    | local  |
| nil      | not   | or    | repeat |
| return   | then  | true  | until  |
| while    | goto  |       |        |



**变量**

```lua
--全局变量
a=1
--局部变量
local a=1
--变量没有赋值为 nil ，同样删除变量只需要赋值为 nil
a=nil
```



**数据类型**

 Lua 是动态类型语言，不用类型定义。 

| 数据类型 | 描述                                                         |
| :------- | :----------------------------------------------------------- |
| nil      | 无效值（在条件表达式中相当于false，做比较如x == "nil" 需要加双引号）。 |
| boolean  | 包含两个值：false和true。                                    |
| number   | 表示双精度类型的实浮点数                                     |
| string   | 字符串由一对双引号或单引号来表示                             |
| function | 由 C 或 Lua 编写的函数                                       |
| userdata | 表示任意存储在变量中的C数据结构                              |
| thread   | 表示执行的独立线路，用于执行协同程序                         |
| table    | Lua 中的表（table）其实是一个"关联数组"（associative arrays），数组的索引可以是数字、字符串或表类型。在 Lua 里，table 的创建是通过"构造表达式"来完成，最简单构造表达式是{}，用来创建一个空表。 |



测试：

```lua
print(type("Hello world"))      --> string
print(type(10.4*3))             --> number
print(type(print))              --> function
print(type(type))               --> function
print(type(true))               --> boolean
print(type(nil))                --> nil
print(type(type(X)))            --> string
```



**流程控制**

```lua
--if语句
if(布尔表达式)
then
   --[ 在布尔表达式为 true 时执行的语句 --]
end

--if else
if(布尔表达式)
then
   --[ 布尔表达式为 true 时执行该语句块 --]
else
   --[ 布尔表达式为 false 时执行该语句块 --]
end

--if嵌套
if( 布尔表达式 1)
then
   --[ 布尔表达式 1 为 true 时执行该语句块 --]
   if(布尔表达式 2)
   then
      --[ 布尔表达式 2 为 true 时执行该语句块 --]
   end
end
```



**循环**

同样的可以使用`goto`和`break`

```lua
--while循环
while(condition)
do
   statements
end

--for循环
--[[
var 从 exp1 变化到 exp2，每次变化以 exp3 为步长递增 var，并执行一次 "执行体"。exp3 是可选的，如果不指定，默认为1。
--]]
for var=exp1,exp2,exp3 do  
    <执行体>  
end  

--特殊的有，可以遍历输出 ipairs是Lua提供的一个迭代器函数，用来迭代数组。
#!/usr/local/bin/lua  
days = {"Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"}  
for i,v in ipairs(days) do  print(v) end  

--repeat until
repeat
   statements
until( condition )
```





嵌lua套循环：

```lua
for init,max/min value, increment
do
   for init,max/min value, increment
   do
      statements
   end
   statements
end

while(condition)
do
   while(condition)
   do
      statements
   end
   statements
end

repeat
   statements
   repeat
      statements
   until( condition )
until( condition )
```



**函数**

```lua
optional_function_scope function function_name( argument1, argument2, argument3..., argumentn)
    function_body
    return result_params_comma_separated
end

-- optional_function_scope:			全局 或者 局部（使用local）
-- result_params_comma_separated: 	函数返回值可以使用逗号隔开
```



例子：

```lua
function maximum (a)
    local mi = 1             -- 最大值索引
    local m = a[mi]          -- 最大值
    for i,val in ipairs(a) do
       if val > m then
           mi = i
           m = val
       end
    end
    return m, mi
end

print(maximum({8,10,23,12,5}))
```



可以使用`...`表示可变长参数

使用` select('#',...)`获取参数长度

使用` select(n,...)`获取第n个参数

```lua
do  
    function foo(...)  
        for i = 1, select('#', ...) do  -->获取参数总数
            local arg = select(i, ...); -->读取参数
            print("arg", arg);  --还可以紧密拼接 print("arg"..arg)
        end  
    end  
 
    foo(1, 2, 3, 4);  
end
--[[
输出：
arg    1
arg    2
arg    3
arg    4
--]]
```



**表**

```lua
-- 初始化表
mytable = {}

-- 指定值
mytable[1]= "Lua"

-- 移除引用 垃圾回收会释放内存
mytable = nil
```



**模块**

定义模块：

```lua
-- 文件名为 module.lua
-- 定义一个名为 module 的模块
module = {}
 
-- 定义一个常量
module.constant = "这是一个常量"
 
-- 定义一个函数
function module.func1()
    io.write("这是一个公有函数！\n")
end

local function func2()
    print("这是一个私有函数！")
end
 
function module.func3()
    func2()
end
 
return module
```



加载使用：

```lua
--[[
require("<模块名>")
或者
require "<模块名>"
--]]
--直接使用
require("module")
print(module.constant)
module.func3()

--定义别名使用
m = require("module")
print(m.constant)
m.func3()
```



### 4.3OpenResty

基于nginx的可伸缩Web平台，外部人员可以通过lua脚本调用nginx内置模块。

https://github.com/openresty



#### 4.3.1安装OpenResty

linux安装OpenResty：

```shell
#添加仓库执行命令
yum install yum-utils
yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo

#执行安装，会安装在默认的路径下/usr/local/openresty
yum -y install openresty
```



#### 4.3.2Nginx

##### 4.3.2.1安装

安装了openresty后默认会在目录下安装nginx，下面是复制的以前的笔记做备忘。

```shell
#编译工具与库文件
yum -y install make zlib zlib-devel gcc-c++ libtool  openssl openssl-devel

#安装PCRE可以让nginx支持Rewrite功能
cd /usr/local/src/
#建议本地下，太卡了
wget https://netix.dl.sourceforge.net/project/pcre/pcre/8.40/pcre-8.40.tar.gz
tar zxvf pcre-8.40.tar.gz
cd pcre-8.40
./configure
make && make install
#查看pcre版本
pcre-config --version

#安装nginx
cd /usr/local/src/
wget http://nginx.org/download/nginx-1.6.2.tar.gz
tar zxvf nginx-1.6.2.tar.gz
cd nginx-1.6.2
./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.40
make
make install
#查看版本
/usr/local/webserver/nginx/sbin/nginx -v

#nginx环境变量设置
vim /etc/profile
#内容
export PATH=$PATH:/usr/local/webserver/nginx/sbin/
#生效
source /etc/profile
nginx -v
```



##### 4.3.2.2基础命令

```shell
#重载
nginx -s reload

#停止
nginx -s stop

#指定配置文件
nginx -c /usr/local/webserver/nginx/conf/nginx.conf
```

启动后可以直接访问ip:80



##### 4.3.2.3启动OpenResty

```shell
/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf
```

<img src="./images/openresty界面.png" style="zoom:67%;" />





### 4.4 测试：数据更新到缓存实现

我们设定用户的请求为：`update_ad?categoryId=xxx`



#### 4.4.1 lua脚本

把数据从mysql查询出来保存到缓存中：

`vim /root/lua-5.3.0/zscript/update_ad.lua`



```lua
ngx.header.content_type="application/json;charset=utf8"
local cjson = require("cjson")
local mysql = require("resty.mysql")

local uri_args = ngx.req.get_uri_args()
local categoryId = uri_args["categoryId"]

local db = mysql:new()
db:set_timeout(1000)
local props = {
	host = "192.168.190.200",
	port = 3306,
	database = "shop_ad",
	user = "root",
	password = "123456"
}

local res = db:connect(props)
local select_sql = "SELECT AD_TITLE, AD_URL, AD_PIC_URL FROM SHOP_AD_CONTENT WHERE AD_STATUS = '1' AND AD_CATEGORY_ID= '"..categoryId.."' "
res = db:query(select_sql)
db:close()

local redis = require("resty.redis")
local red = redis:new()
red:set_timeout(2000)
local ip ="192.168.190.200"
local port = 6379
red:connect(ip,port)
red:auth("123456")
red:set("ad_"..categoryId,cjson.encode(res))
red:close()

ngx.say("{flag:true}")
```



#### 4.4.2 nginx配置

server下面添加：

```nginx
server{
	listen 80;
    server_name localhost;
    
    #把用于请求update_ad?categoryId=xxx交给脚本处理
    #脚本地址：/root/lua-5.3.0/zscript/update_ad.lua
    location /update_ad {
        content_by_lua_file /root/lua-5.3.0/zscript/update_ad.lua;
    }
}
```



完成之后重启nginx：

```shell
/usr/local/openresty/nginx/sbin/nginx -s reload
```



#### 4.4.3 脚本访问权限

如果直接访问会返回404，之后查看nginx日志：

```shell
tail -f /usr/local/openresty/nginx/logs/error.log
cannot open /root/lua-5.3.0/zscript/update_ad.lua: Permission denied, 
```



需要在nginx的配置文件上加上用户配置：

```shell
vim /usr/local/openresty/nginx/conf/nginx.conf

#user  nobody;
user root root;
```



完成之后重启nginx：

```shell
/usr/local/openresty/nginx/sbin/nginx -s reload
```



测试：

http://192.168.190.200/update_ad?categoryId=3



### 4.5 读取缓存数据

完整的路径应该是首选获取nginx缓存，如果缓存不存在获取redis缓存，不存在获取mysql数据。

我们设定用户的请求为：`read_ad?categoryId=xxx`

#### 4.5.1 lua脚本

`vim /root/lua-5.3.0/zscript/read_ad.lua`



这里的`ngx.shared.dis_cache`是定义的nginx缓存模块

```lua
ngx.header.content_type="application/json;charset=utf8"
local uri_args = ngx.req.get_uri_args()
local categoryId = uri_args["categoryId"]

local cache_ngx = ngx.shared.dis_cache;
local contentCache = cache_ngx:get('ad_cache_'..categoryId);
ngx.say('nginx',contentCache)

if contentCache == "" or contentCache == nil then
    local redis = require("resty.redis")
    local red = redis:new()
    red:set_timeout(2000)
    red:connect("192.168.190.200",6379)
    red:auth("123456")
    --单位ms
    red:set_timeout(2*60*1000)
    local rescontent = red:get("ad_"..categoryId)
    ngx.say('redis',rescontent)
    
    if ngx.null == rescontent then
        local cjson = require("cjson")
		local mysql = require("resty.mysql")
		local db = mysql:new()
		db:set_timeout(1000)
        local props = {
            host = "192.168.190.200",
            port = 3306,
            database = "shop_ad",
            user = "root",
            password = "123456"
        }
		local res = db:connect(props)
        local select_sql = "SELECT AD_TITLE, AD_URL, AD_PIC_URL FROM SHOP_AD_CONTENT WHERE AD_STATUS = '1' AND AD_CATEGORY_ID= '"..categoryId.."' "
		res = db:query(select_sql)
        local resJson = cjson.encode(res)
        red:set("ad_"..categoryId,resJson)
        ngx.say('mysql',resJson)
		db:close()
    else
        -- nginx缓存1分钟
        cache_ngx:set('ad_cache_'..categoryId, rescontent, 1*60)
        ngx.say(rescontent)
    end
    red:close()
else
    ngx.say(contentCache)
end
```



#### 4.5.2 nginx配置

`vim /usr/local/openresty/nginx/conf/nginx.conf`



我们需要添加缓存模块和路由信息：

```nginx
user root root;
worker_processes  1;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #cache:定义缓存模块，大小为128M
    lua_shared_dict dis_cache 128m;

    sendfile        on;
    keepalive_timeout  65;

    server {
        listen       80;
        server_name  localhost;

        location / {
            root   html;
            index  index.html index.htm;
        }

        location /read_ad {
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```



重启：`/usr/local/openresty/nginx/sbin/nginx -s reload`





### 4.6 nginx限流

实现方式：

- 控制速率
- 控制并发连接数



#### 4.6.1 控制速率



##### 4.6.1.1 拒绝超出响应的请求

`vim /usr/local/openresty/nginx/conf/nginx.conf`



```nginx
http{
    ......
    
    #限流设置 binary_remote_addr根据请求地址进行限流
    #contentRateLimit 缓存空间名称，大小为10M
    #rate=2r/s 每秒两个请求
    limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s;
    
    server{
         location /read_ad {
            #使用限流配置
            limit_req zone=contentRateLimit;
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
    }
}
```

>binary_remote_addr 是一种key，表示基于 remote_addr(客户端IP) 来做限流，binary_ 的目的是压缩内存占用量。
>
>zone：定义共享内存区来存储访问信息， myRateLimit:10m 表示一个大小为10M，名字为myRateLimit的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。
>
>rate 用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求.我们这里设置成2 方便测试。



重启测试：`./nginx -s reload`

<img src="./images/nginx限流错误-浏览器.png" style="zoom:67%;" />

访问错误日志：

`2020/08/28 01:05:48 [error] 1642#1642: *31 limiting requests, excess: 0.300 by zone "contentRateLimit", client: x.x.x.x, server: localhost, request: "GET /read_ad?categoryId=1 HTTP/1.1", host: "192.168.190.200"`



##### 4.6.1.2 处理突发流量

在上面的例子`rate=2r/s`，也就是500ms只能处理一个请求，但是如果我们希望处理突发流量，把多余的请求先放入队列等待。

我们可以在`limit_req`后面加入`burst`字段，如下：

`limit_req zone=contentRateLimit burst=20;`

如果同时进入21个请求，那么多余的20个请求将会进入队列等待。当然如果超出21个请求，多余的会被拒绝。



当然，如果一直排队也会出现等待时间过长，比如这里的500ms处理一个请求，那么队列中最后一个请求要等待到10s之后了，我们可以加入`nodelay`参数：

```nginx
http{
    ......
    
    #限流设置 binary_remote_addr根据请求地址进行限流
    #contentRateLimit 缓存空间名称，大小为10M
    #rate=2r/s 每秒两个请求
    limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s;
    
    server{
         location /read_ad {
            #使用限流配置
            limit_req zone=contentRateLimit burst=5 nodelay;
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
    }
}
```

此时如果同时有6个请求到达，那么队列中还有位置，nginx就会立即转发（想防御这6个事并行处理的），超出缓冲队列的请求会直接拒绝。



#### 4.6.2 控制并发量

`ngx_http_limit_conn_module`提供了并发量控制的能力，主要是利用`limit_conn_zone`和`limit_conn`两个指令，利用连接数限制某一个用户的**IP连接数量**来控制流量。



注意：只有服务器正在处理请求并且已经读取了整个请求头的时候，才会计算为有效连接。



##### 4.6.2.1 单个IP并发限制

编写本地测试接口：

端口8001，ip：192.168.190.1

```java
@RestController
public class TestController {
    @GetMapping("sleep")
    public String sleep() {
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return "sleep";
    }
}
```





配置nginx到本地测试：

```nginx
http{
	......
    #根据IP地址来限制，存储内存大小为10M addr是命名
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    
    server{
        ......
        #转发到本地测试接口
        location /sleep {
            #配置addr，表示每秒可以有两个请求
            limit_conn addr 2;
            proxy_pass http://192.168.190.1:8001/sleep;
        }
    }
}
```



使用JMeter测试可以看出来，每s第三个请求直接失败。



##### 4.6.2.2 固定接口并发限制

我们之前是通过对统一IP地址进行访问并发的限制，同时，我们可以对所有的请求也进行并发限制。

采用之前的接口来做测试，增加nginx的配置：

```nginx
http{
	......
    #根据IP地址来限制，存储内存大小为10M addr是命名
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    #对固定接口限制总的并发量
    limit_conn_zone $server_name zone=curserver:10m;
    
    server{
        ......
        #转发到本地测试接口
        location /sleep {
            #配置addr，表示每秒可以有两个请求
            limit_conn addr 2;
            #配置curserver，表示每s这个接口总共可以接收10个请求
            limit_conn curserver 10;
            proxy_pass http://192.168.190.1:8001/sleep;
        }
    }
}
```

也就是说，每秒sleep接口可以访问10次，但是来源于同一IP的请求只能有2个。



### 4.7 Canal同步数据

只要是有关缓存的问题就会涉及到数据的更新，不管我们是定时更新缓存数据还是在变化的时候马上写缓存，都存在一定的问题（更新不及时或者消耗接口时间）。同样的，在这个例子里面，我们希望有一个服务能够监听数据的更改，实时刷新缓存。



使用之前，我们需要在mysql里面开启日志



#### 4.7.1 工作原理

有关canal的介绍可以看官方的文档：https://github.com/alibaba/canal

<img src="./images/mysql主备复制原理.jpg" style="zoom: 80%;" />

上图展示了mysql的主从复制原理：

- MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看)
- MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)
- MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据



canal 工作原理

- canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
- MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
- canal 解析 binary log 对象(原始为 byte 流)



<img src="./images/Canal原理.png" style="zoom: 60%;" />

canal获取到数据之后，可以把数据刷新到Redis缓存中，在其他地方，也可以把数据写入ES、MySQL等处理。



#### 4.7.2 mysql开启binlog模式和创建同步账号

**开启binlog模式**

 我们这里是用docker安装的mysql，所以里面基本的环境都没有，可以使用` apt-get update`和`apt-get install vim`来安装vim

```shell
#进入mysql容器
docker exec -it z-mysql /bin/bash

#连接
mysql -h localhost -uroot -p123456

#查看mysql是否开启binlog模式，也就是log_bin的值如果ON则是开启
SHOW VARIABLES LIKE '%log_bin%';

#修改配置文件
vim /etc/mysql/mysql.conf.d/mysqld.cnf

[mysqld]
......

#binlog setting,第一个log-bin是二进制存储目录，第二个是当前数据库的唯一编号
log-bin=/var/lib/mysql/mysql-bin
server-id=12345

#修改完成之后，重启mysql服务或者直接docker restart z-mysql
/etc/init.d/mysql restart
```



**创建同步账号**

使用root账号创建用户并授权：

```shell
#进入mysql容器
docker exec -it z-mysql /bin/bash

#进入mysql
mysql -h localhost -uroot -p123456

#创建账号用于同步数据
#创建账号，账号名密码canal，'%'表示可以从任意主机登录
create user 'canal'@'%' IDENTIFIED by 'canal';
#授权：*.*表示所有数据库所有表
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT, SUPER ON *.* TO 'canal'@'%';
#权限生效
FLUSH PRIVILEGES;
```



#### 4.7.3 Canal容器安装

```powershell
#下载镜像
docker pull canal/canal-server

#创建容器
docker run -p 11111:11111 --name z-canal -d canal/canal-server 

#设置自启动
docker update --restart=always z-canal

#进入容器
docker exec -it z-canal /bin/bash

pwd
/home/admin
yum -y install vim

------------------------------------------------
#修改canal自身配置
vim canal-server/conf/canal.properties

#这里的id和mysql里面的server-id都表示服务的id，不能和mysql的server-id重复
canal.id = 1

------------------------------------------------
#同步配置
vim canal-server/conf/example/instance.properties

# 指定需要同步的数据库地址
# position info
canal.instance.master.address=127.0.0.1:3306

canal.instance.dbUsername=canal
canal.instance.dbPassword=canal

#数据库表的正则匹配，这里表示所有数据库(.*)所有表(.*)，中间(\\.)转义.
# table regex
canal.instance.filter.regex=.*\\..*


#配置完成后重启
docker restart z-canal
```



#### 4.7.4 搭建canal微服务





