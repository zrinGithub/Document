# 商城项目笔记

[TOC]



## 1 项目搭建

### 1.1 虚拟机

软件使用`VMware® Workstation 15 Pro`，版本`15.5.1 build-15018445`

镜像使用`CentOS-7-x86_64-Minimal-1908.iso`（docker安装需要）

因为之前的笔记比较散，所以这里尽量做最全面的部署说明：



#### 1.1.1 安装

这个镜像就是最小镜像，所以没有图形化界面：

进入界面，选择`Install CentOs7`之后随便选。

设定root密码123456



##### 1.1.1.1 上传下载文件

`yum -y install lrzsz `

#### 1.1.2 网络配置

##### 1.1.2.1 网关与ip

首先需要查看当前虚拟机网关的地址，具体位置：

`控制面板\网络和 Internet\网络连接`

查看VMnet8的网关地址



也可以直接在管理员模式下启动Vmware，然后点击菜单->编辑->虚拟网络编辑器里面查看

```shell
编辑
vim /etc/sysconfig/network-scripts/ifcfg-ens33 

内容
......
BOOTPROTO=static
NAME=ens33
DEVICE=ens33
ONBOOT=yes
IPADDR=192.168.190.200
NETMASK=255.255.255.0
GATEWAY=这里就是网关地址
DNS1=8.8.8.8

重启
service network restart
```



如果是复制的机器，建议在开启的时候直接选择移动的机器，然后修改ip地址即可，如果选择复制，可能需要设计网卡的修改。



##### 1.1.2.2 关闭防火墙

因为后面需要开放端口，这里我们直接关闭防火墙

```shell
#查看防火墙状态
firewall-cmd --state

#停止firewall
systemctl stop firewalld.service

#禁止firewall开机自启
systemctl disable firewalld.service
```



#### 1.1.3 Docker安装

参考官网：https://docs.docker.com/install/linux/docker-ce/centos/

安装需要CentOs7主版本

docker包含 EE企业版本和CE社区版本。



官网关于stable/nightly/test三个更新渠道的说明

> - **Stable** gives you latest releases for general availability.
> - **Test** gives pre-releases that are ready for testing before general availability.
> - **Nightly** gives you latest builds of work in progress for the next major release.





##### 1.1.3.1 使用Docker Repository来安装

官网推荐设置Docker repository来安装：



- 删除旧版本

```shell
$ sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```



- 安装`yum-utils`包（提供`yum-config-manager`功能）并设定稳定的仓库

```shell
$ sudo yum install -y yum-utils

$ sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
```



- 官方建议安装nightly或者test更新渠道

```shell
开启nightly repository
$ sudo yum-config-manager --enable docker-ce-nightly

启动test
$ sudo yum-config-manager --enable docker-ce-test

关闭nightly或者test使用--disable即可
$ sudo yum-config-manager --disable docker-ce-nightly
```



- 安装特定版本

```shell
查看版本列表
$ sudo yum list docker-ce --showduplicates | sort -r

docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable
docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable
docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable
docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable

安装时候使用docker-ce加上版本号，如docker-ce-18.06.0.ce('-'前面为版本号)
$ sudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io
```



- 安装最新版本

```shell
$ sudo yum install docker-ce docker-ce-cli containerd.io
```



- 启动

```shell
$ sudo systemctl start docker
```



- 测试

```shell
$ sudo docker run hello-world
```



##### 1.1.3.2 使用安装包

- 下载版本 https://download.docker.com/linux/centos/7/x86_64/ 选择安装版本
- 安装：`yum install /path/to/package.rpm`
- 启动：`systemctl start docker`
- 测试：`docker run hello-world`



##### 1.1.3.3 使用阿里docker社区版yum源安装

```shell
 # 安装wget
 yum install wget
 
 # 下载阿里云docker社区版yum源
 cd /etc/yum.repos.d/
 wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
 
 # 查看docker安装包
 yum list | grep docker
 
 # 安装docker ce社区版本
 yum install -y docker-ce.x86_64
 
 # 设置开机启动
 systemctl enable docker
 
 # 更新xfsprogs
 yum -y update xfsprogs
 
 # 启动docker
 systemctl start docker

 # 查看版本
 docker version
 
 # 查看详细信息
 docker info
```



#### 1.1.4 设置Docker容器自动启动

```shell
docker update --restart=always CONTAINER_NAME/CONTAINER_ID
```



#### 1.1.5 docker安装mysql

```shell
# 查看可用版本
docker search mysql

# 拉取官方镜像
docker pull mysql:5.7

#运行，-p前面是宿主机地址，后面是容器地址
docker run -itd --name z-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7

#设定开机自启
docker update --restart=always z-mysql

#进入容器
docker exec -it z-mysql /bin/bash
```





#### 1.1.6 docker安装redis

https://hub.docker.com/_/redis/



因为涉及远程连接，需要挂载外部文件

```shell
mkdir -p /root/docker/redis/conf

#这里我直接找官网http://download.redis.io/releases/的redis.conf文件到/root/docker/redis/conf目录下
#这里配置密码，可以吧protected-mode打开
vim /root/docker/redis/conf/redis.conf
#取消访问地址限制
#bind 127.0.0.1 
#设置访问密码，redis需要认证使用命令： auth myPassword
#或者在连接的时候./redis-cli -h 192.168.190.200 -p 6379 -a 123456
protected-mode no
requirepass 123456  
```



镜像：

```shell
# 查看可用版本
docker search redis

# 拉取官方镜像
docker pull redis

#运行，-p前面是宿主机地址，后面是容器地址
docker run -itd --name z-redis -p 6379:6379 \
-v /root/docker/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf \
redis redis-server /usr/local/etc/redis/redis.conf

#设定开机自启
docker update --restart=always z-redis

#进入容器
docker exec -it z-redis /bin/bash
```



#### 1.5.7 docker镜像打包和导入

有的时候我们需要使用自己的镜像：

```shell
#保存压缩镜像到本地
docker save IMAGE_ID | gzip > xxx.tar.gz
#发送到安装机器
scp xxx.tar.gz root@192.168.190.200:/root
#解压并加载到本地仓库
gunzip -c xxx.tar.gz | docker load
#重命名
docker tag IMAGE_ID xxx
```





### 1.3 基础代码结构

#### 1.3.1 父工程

父工程主要负责导入springboot、springcloud



> parent标签主要用于实现复用父类的依赖以及统一管理依赖的版本号。





### 1.4 服务地址与端口

#### 1.4.1 项目服务

| 服务               | 说明           | 端口 |
| ------------------ | -------------- | ---- |
| eureka-server      | eureka注册中心 | 8000 |
| fastdfs-ops        | fastdfs操作    | 8001 |
| shop-service-canal | canal          | 8002 |



#### 1.4.2 服务配置

均使用一台虚拟机安装，所以地址都在`192.168.190.200`

| 服务            | 端口                | 相关配置文件                                                 |
| --------------- | ------------------- | ------------------------------------------------------------ |
| fastdfs tracker | 22122 nginx端口8080 | nginx配置文件：/etc/nginx/conf/nginx.conf<br />tracker配置文件：/etc/fdfs/tracker.conf |
| fastdfs storage | 23000 nginx端口8080 | nginx配置文件：/etc/nginx/conf/nginx.conf<br />storage配置文件：/etc/fdfs/storage.conf<br />存储位置：/data/fast_data |
| redis           | 6379                |                                                              |
| mysql           | 3306                |                                                              |
| openresty nginx | 80                  | /usr/local/openresty/nginx/                                  |
| canal           | 11111               | canal-server/conf/example/instance.properties<br/>canal-server/conf/canal.properties |
| es              | 9200                | /usr/share/elasticsearch/config/elasticsearch.yml            |
|                 | 5601                |                                                              |



### 1.5 Jmeter

Jmeter可以用于负载和性能测试。

官网：https://jmeter.apache.org/



#### 1.5.1 JMeter安装

本地先要有jdk环境，这里本地的jdk是1.8。



JMeter下载地址 ： https://jmeter.apache.org/download_jmeter.cgi

解压后点击bin路径下的jmeter.bat即可



## 2 fastDfs

fastDfs是开源的轻量级分布式文件系统，包含tracker server、storage server。

tracker负责复杂均衡和调度，上传的时候寻找可用的storage来存储。

<img src="./images/fastdfs上传.png" style="zoom:67%;" />





### 2.1 Docker安装fastDfs

- 拉取镜像：

  ```shell
  docker pull morunchang/fastdfs
  
  #因为拉取太慢了，我也不知道能不能拉下来，所以从其他虚拟机拷贝的
  #保存压缩镜像到本地
  docker save a729ac95698a | gzip > fastdfs.tar.gz
  #发送到安装机器
  scp fastdfs.tar.gz root@192.168.190.200:/root
  #解压并加载到本地仓库
  gunzip -c fastdfs.tar.gz | docker load
  #重命名
  docker tag a729ac95698a morunchang/fastdfs
  ```

  

- 运行tracker：

  ```shell
  docker run -d --name tracker --net=host morunchang/fastdfs sh tracker.sh
  --net:使用的网路模式为host，也就是共享主机network namespace可以直接访问主机的网络信息，缺点是两个容器的端口必须不同，因为都是使用主机的接口。
  ```

  

- 运行storage：

  ```shell
docker run -d --name storage --net=host -e TRACKER_IP=<your tracker server address>:22122 -e GROUP_NAME=<group name> morunchang/fastdfs sh storage.sh
  
  --net:使用的网路模式为host，也就是共享主机network namespace可以直接访问主机的网络信息，缺点是两个容器的端口必须不同，因为都是使用主机的接口。
  -e添加到环境变量
  	TRACKER_IP  track机器的ip
  	GROUP_NAME	组名，也就是storage的组，新的storage服务器组名需要改变
  
  
  #本例使用
  docker run -d --name storage --net=host -e TRACKER_IP=192.168.190.200:22122 -e GROUP_NAME=group1 morunchang/fastdfs sh storage.sh
  ```
  
  
  
- storage内部修改nginx配置

  ```shell
  #进入容器
  docker exec -it storage /bin/bash
  #修改nginx配置
  vim /etc/nginx/conf/nginx.conf
  
  #里面已经有配置了，nginx端口8080
  location ~ /M00 {
  	root /data/fast_data/data;
      ngx_fastdfs_module;
  }
  #如果不希望浏览器缓存的话（比如删除希望立即删除）
  add_header Cache-Control no-store;
  
  #退出容器
  exit
  
  #重启storage容器
  docker restart storage
  ```



- 查看启动的容器：`docker ps`

- 开机启动设置：

  ```shell
  docker update --restart=always tracker
  docker update --restart=always storage
  ```

- 查看配置文件

  ```shell
  docker exec -it storage /bin/bash
  cd /etc/fdfs/
  vim storage.conf
  #里面的store_path0表示文件的位置
  store_path0=/data/fast_data
  #tracker的地址
  tracker_server=192.168.211.132:22122
  ```

  

### 2.2 fastDfs服务代码

#### 2.2.1 安装依赖

看了几个不同的项目，基本都是使用github上面的这个项目： https://github.com/happyfish100/fastdfs-client-java

文档里面写得很清楚了，使用idea的话install一下就可以了。

安装到本地库之后使用pom导入（注意版本号和安装的一样）：

```xml
        <dependency>
            <groupId>org.csource</groupId>
            <artifactId>fastdfs-client-java</artifactId>
            <version>1.29-SNAPSHOT</version>
        </dependency>
```



#### 2.2.2 配置文件

`application.yml`

```yaml
spring:
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
  application:
    name: fastdfs-ops
server:
  port: 8001
eureka:
  client:
    service-url:
      defaultZone: http://test:123456@127.0.0.1:8000/eureka/
  instance:
    prefer-ip-address: true
feign:
  hystrix:
    enabled: true
```



`fdfs_client.conf`

```properties
connect_timeout = 60
network_timeout = 60
charset = UTF-8
http.tracker_http_port = 8080
tracker_server = 192.168.190.200:22122
```



启动类：

```java
@SpringBootApplication
@EnableEurekaClient
@EnableSwagger2
public class FastDFSApplication {
    public static void main(String[] args) {
        SpringApplication.run(FastDFSApplication.class, args);
    }
}
```



#### 2.2.3 文件上传下载实现

包装类：

```java
@Data
@Accessors(chain = true)
public class FastDFSFile {
    //文件名字
    private String name;
    //文件内容
    private byte[] content;
    //文件扩展名
    private String ext;
    //文件创建作者
    private String author;
}
```



-----



Client代码：

```java
@Component
@Slf4j
public class FastDFSClient {
    private TrackerServer trackerServer;
    private TrackerClient trackerClient;
    private StorageServer storageServer;
    //使用StorageClient1而不是StorageClient只是为了方便操作组名和文件路径（想一下你不用自己去加分隔符了）
    private StorageClient1 storageClient;

    //设定默认的配置，可以在application.yml里面修改
    @Value("${fastdfs.http.permit.types:png,jpg,jpeg,doc,xls,pdf,bmp,gif}")
    private String permitTypes;
    private String[] types;
    //这里的前缀就是服务位置+端口号
    private String prefix;

    @PostConstruct
    public void init() throws Exception {
        String path = new ClassPathResource("fdfs_client.conf").getFile().getAbsolutePath();
        ClientGlobal.init(path);
        trackerClient = new TrackerClient();
        trackerServer = trackerClient.getTrackerServer();
        storageServer = null;
        storageClient = new StorageClient1(trackerServer, storageServer);
        types = permitTypes.split(",");
        prefix = "http://" + trackerServer.getInetSocketAddress().getHostString()
                + ":" + ClientGlobal.getG_tracker_http_port() + "/";
    }

    /**
     * 上传输入流
     *
     * @param file 包装的文件数据
     * @return 文件路径
     */
    public String uploadFile(FastDFSFile file) throws Exception {
        //1.判定文件类型是否合法
        boolean permit = false;
        for (String type : types) {
            if (type.equals(file.getExt())) {
                permit = true;
                break;
            }
        }

        if (!permit) {
            String errMsg = "上传文件格式不允许";
            log.error(errMsg);
            throw new Exception(errMsg);
        }
        //2.封装参数
        NameValuePair[] metas = new NameValuePair[2];
        metas[0] = new NameValuePair("name", file.getName());
        metas[1] = new NameValuePair("author", file.getAuthor());
        //3.上传文件
        String relativePath = storageClient.upload_file1(file.getContent(), file.getExt(), metas);
        return prefix + relativePath;
    }

    /**
     * 删除文件
     *
     * @param filePath 文件路径
     * @return 返回操作结果判定
     * @throws IOException
     * @throws MyException
     */
    public boolean deleteFile(String filePath) throws IOException, MyException {
        return 0 == storageClient.delete_file1(StringUtils.replace(filePath, prefix, ""));
    }

    /**
     * 获取下载文件流
     *
     * @param filePath 文件完整路径
     * @return 返回输入流
     * @throws IOException
     * @throws MyException
     */
    public InputStream downloadFileStream(String filePath) throws IOException, MyException {
        byte[] content = storageClient.download_file1(filePath);
        return new ByteArrayInputStream(content);
    }

    /**
     * 获取下载文件Base64编码
     *
     * @param filePath 文件完整路径
     * @return 返回BASE64编码
     * @throws IOException
     * @throws MyException
     */
    public String downloadFileBase64(String filePath) throws IOException, MyException {
        try (InputStream inputStream = downloadFileStream(filePath)) {
            byte[] bytes = IOUtils.toByteArray(inputStream);
            String fileType = StringUtils.substringAfterLast(filePath, ".");
            String encodeStr = Base64.getEncoder().encodeToString(bytes);
            return String.format("data:image/%s;base64,", fileType) + encodeStr;
        } catch (Exception e) {
            return null;
        }
    }
}

```



-----



Controller代码：

```java
@RestController
@RequestMapping("fastdfs")
@Slf4j
public class FastDFSController {
    @Resource
    private FastDFSClient client;

    @PostMapping("upload")
    public RespVo<String> upload(MultipartFile file) {
        if (file == null) {
            return new RespVo<>(false, null, "文件不存在");
        }

        String filename = file.getOriginalFilename();
        if (StringUtils.isEmpty(filename)) {
            return new RespVo<>(false, null, "文件不存在");
        }

        try {
            String ext = filename.substring(filename.lastIndexOf(".") + 1);
            //TODO: 这里结合后面的权限校验把申请用户填进去
            FastDFSFile dfsFile = new FastDFSFile().setContent(file.getBytes()).setExt(ext).setName(filename).setAuthor("root");
            String fileDfsPath = client.uploadFile(dfsFile);
            return new RespVo<>(true, fileDfsPath, "文件上传成功");
        } catch (Exception e) {
            log.error("文件上传失败", e);
            return new RespVo<>(false, null, "文件上传失败");
        }
    }

    @GetMapping("delete")
    public RespVo<String> delete(@RequestParam("filePath") String filePath) throws IOException, MyException {
        if (client.deleteFile(filePath))
            return new RespVo<>(true, null, "文件删除成功");
        return new RespVo<>(false, null, "文件删除失败");
    }
}
```





#### 2.2.4 测试

验证文件：

```shell
#进入容器
docker exec -it storage /bin/bash

cd /etc/fdfs/
```





## 3 商品模型

根据业务不同，产商品模型的关联关系不同，这里采用B2C的模式构建产商品模型：



### 3.1 SPU

SPU: Standard Product Unit 标准产品单位，一般理解为一款商品。



这里使用的类目字段表示第三级类目，有的需求里面可以在任意类目下创建产品，也就是这里的`CATEGORY_ID`不一定是三级类别。

为了快速进行单表查询，一般不仅仅展示最后一级类目，会把三级的类别都作为字段存储。

```mysql
CREATE TABLE `SHOP_SPU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SPU_ID` varchar(64) DEFAULT NULL COMMENT 'SPU ID',
  `SPU_NAME` varchar(64) DEFAULT NULL COMMENT '名称',
  `TITLE` varchar(64) DEFAULT NULL COMMENT '标题',
  `SPU_PIC_URL` varchar(2000) DEFAULT NULL COMMENT '图片地址',
  `DESCRIPTION` varchar(512) DEFAULT NULL COMMENT '描述',
  `CATEGORY_ID` varchar(36) NOT NULL COMMENT '三级类别ID',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '上下架状态，0新建，1已下架，2已上架',
  `IS_HOT` tinyint(1) NOT NULL DEFAULT '0' COMMENT '是否是热销产品，0否，1是',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `LIST_TIME` datetime DEFAULT NULL COMMENT '上架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELIST_TIME` datetime DEFAULT NULL COMMENT '下架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PRODUCT_ID_INDEX` (`SPU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SPU产品数据';
```



### 3.2 SKU

SKU: Stock Keeping Unit 库存单位，通过SPU指定规格参数生产，一般理解为最小销售/库存单位。



一般为了快速进行单表查询，也会把类别、品牌、评价数的字段加到表里面

```mysql
CREATE TABLE `SHOP_SKU` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU ID',
  `SPU_ID` varchar(64) NOT NULL COMMENT '关联SPU ID',
  `PRICE` int(9) NOT NULL DEFAULT '0' COMMENT '价格,单位：分',
  `QUANTITY` int(4) DEFAULT NULL COMMENT '库存数量',
  `SKU_PIC_URL` varchar(256) DEFAULT NULL COMMENT '图片地址',
  `STATUS` tinyint(4) NOT NULL DEFAULT '0' COMMENT '上下架状态，0新建，1已下架，2已上架',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建日期（格式：yyyy-MM-dd HH:mm:ss）',
  `LIST_TIME` datetime DEFAULT NULL COMMENT '上架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELIST_TIME` datetime DEFAULT NULL COMMENT '下架时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_TIME` datetime DEFAULT NULL COMMENT '修改日期（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT 'sku最后修改人',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SKU_ID_INDEX` (`SKU_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU商品表';
```



### 3.3 类别、参数与自定义参数

**类别表：**

```mysql
CREATE TABLE `SHOP_CATEGORY` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(36) NOT NULL COMMENT '类别ID',
  `CATEGORY_NAME` varchar(128) NOT NULL COMMENT '类别名称',
  `CATEGORY_LEVEL` tinyint(2) NOT NULL DEFAULT '0' COMMENT '类别等级',
  `PARENT_ID` varchar(36) DEFAULT NULL COMMENT '父ID（一级分类的 PARENT_ID = 0）',
  `SORT` int(11) DEFAULT NULL COMMENT '排序',
  `REMARK` varchar(512) DEFAULT NULL COMMENT '备注',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建者',
  `CREATE_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `CATEGORY_STATUS` tinyint(1) NOT NULL DEFAULT '1' COMMENT '状态，0禁用，1启用',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `CATEGORY_ID_INDEX` (`CATEGORY_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别表';
```



-----



**参数表：**

```mysql
CREATE TABLE `SHOP_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `PARAM_ID` varchar(64) NOT NULL COMMENT '参数ID',
  `PARAM_TYPE` tinyint(1) NOT NULL COMMENT '类型（0规格属性，1其他属性）',
  `PARAM_NAME` varchar(64) NOT NULL COMMENT '名称',
  
  `ORDER_NUM` int(11) DEFAULT '0' COMMENT '排序',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`PARAM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='参数表';
```

对应下面这张图来看：`PARAM_TYPE`这个字段主要还是区分**规格参数**和sku之间有差别的参数（其他参数）。

**规格参数**是指能够区分出sku的参数。具体来说，产品关联了类别id，找到对应的规格参数，通过勾选规格参数的笛卡尔积生成SKU。

**其他参数**在很多业务上是不需要的，因为大多数时间产商品都是同一类，如下图像库存数量、重量都是必填项，属于SKU表中的固定字段，但是如果我们的商城还存在没有重量、库存这种指标的商品（比如视频、游戏账号），那么可以把这些参数作为其他参数。

<img src="./images/规格参数与sku.png" style="zoom: 50%;" />



**参数类别关联：**规格参数和类别关联起来，根据业务决定是只能在三级类别上面挂载参数还是任意级别。

```mysql
CREATE TABLE `SHOP_CATEGORY_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(64) NOT NULL COMMENT 'CATEGORY_ID',
  `PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`CATEGORY_ID`,`PARAM_ID`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别-参数关联';
```

这里参数是关联的类别，使用SPU关联类别来找到参数。

根据需求有时候可能会在SPU这个级别重新制定参数，也就是类别的参数可能只是作为一个选择，那么我们只选定SPU需要的参数，这个时候需要再有一个关联SPU和参数的表。



----



**自定义参数表：**

**自定义参数**作为sku规格以外的*补充参数*（比如生产厂商、物流仓库地址等不影响价格的因素，当然最重要的是不影响sku库存最小单位）。

这个表设计和参数表一样，需要挂载到类别上面，作为SPU级别的补充参数。

```mysql
CREATE TABLE `SHOP_CUSTOM_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CUSTOM_PARAM_ID` varchar(64) NOT NULL COMMENT '自定义参数ID',
  `CUSTOM_PARAM_NAME` varchar(64) NOT NULL COMMENT '名称',
  
  `ORDER_NUM` int(11) DEFAULT '0' COMMENT '排序',
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `CUSTOM_PARAM_ID_INDEX` (`CUSTOM_PARAM_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='自定义参数表';

CREATE TABLE `SHOP_CATEGORY_CUSTOM_PARAM` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `CATEGORY_ID` varchar(64) NOT NULL COMMENT 'CATEGORY_ID',
  `CUSTOM_PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_ID_INDEX` (`CATEGORY_ID`,`PARAM_ID`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='类别-参数关联';
```





**SKU参数值关联：**

以前很多项目喜欢使用json的格式来保存像规格参数这种数据，实际上为了快速进行单表查询，可以把这种字段作为冗余保存在sku的表中，但是为了方便对参数进行定义和CRUD，最好还是把这些数据作为单独的表分割出来。

所以我们可以通过SKU_ID关联到属性值：

```mysql
CREATE TABLE `SHOP_SKU_PARAM_VALUE` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `SKU_ID` varchar(64) NOT NULL COMMENT 'SKU的ID',
  `PARAM_VALUE_ID` varchar(64) NOT NULL COMMENT '参数值ID',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `SKU_PARAM_VALUE_ID_UKEY` (`SKU_ID`,`PARAM_VALUE_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='SKU - 参数值表';
```



**参数值：**

```mysql
CREATE TABLE `SHOP_PARAM_VALUE` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `PARAM_VALUE_ID` varchar(64) NOT NULL COMMENT 'PARAM_VALUE_ID',
  `PARAM_ID` varchar(64) NOT NULL COMMENT 'PARAM_ID',
  `PARAM_VALUE` varchar(256) NOT NULL COMMENT '产品属性值',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `PARAM_VALUE_ID_INDEX` (`PARAM_VALUE_ID`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=896 DEFAULT CHARSET=utf8 COMMENT='参数值表';
```





## 4 缓存实现-首页广告位示例

### 4.1基本思路

首页的内容对响应速度敏感，所以我们需要使用缓存存储首页广告位。

<img src="./images/广告缓存方案.png" style="zoom:67%;" />



### 4.2表结构

```mysql
CREATE TABLE `SHOP_AD_CONTENT` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `AD_ID` varchar(64) NOT NULL COMMENT '广告ID',
  `AD_CATEGORY_ID` varchar(64) NOT NULL COMMENT '广告类目ID',
  `AD_TITLE` varchar(256) NOT NULL COMMENT '标题',
  `AD_URL` varchar(256) DEFAULT NULL COMMENT '连接地址',
  `AD_PIC_URL` varchar(256) DEFAULT NULL COMMENT '图片地址',
  `AD_STATUS` tinyint(1) NOT NULL DEFAULT '1' COMMENT '状态，0禁用，1启用',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `AD_ID_INDEX` (`AD_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='广告表';

CREATE TABLE `SHOP_AD_CATEGORY` (
  `PK_ID` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
  `AD_CATEGORY_ID` varchar(64) NOT NULL COMMENT '广告类目ID',
  `AD_CATEGORY_NAME` varchar(256) NOT NULL COMMENT '广告类目名称',
  
  `CREATE_BY` varchar(128) DEFAULT NULL COMMENT '创建人员编号',
  `CREATE_TIME` datetime DEFAULT NULL COMMENT '创建时间（格式：yyyy-MM-dd HH:mm:ss）',
  `MODIFY_BY` varchar(128) DEFAULT NULL COMMENT '修改者',
  `MODIFY_TIME` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `DELETED_FLAG` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除标记（0：正常，1：已删除）',
  `ORDER_NUM` int(12) DEFAULT '0' COMMENT '顺序',
  PRIMARY KEY (`PK_ID`) USING BTREE,
  UNIQUE KEY `AD_CATEGORY_ID_INDEX` (`AD_CATEGORY_ID`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='广告类目表';
```



### 4.2 Lua脚本语言

轻量脚本语言，c编写主要是为了提供扩展定制功能（脚本的另外一种说法）。

参考学习： https://www.runoob.com/lua/lua-tutorial.html 

特点：

- 支持面向过程 (Procedure Oriented)和函数式编程(Functional Programming)  
- 仅使用通用类型的表
- 闭包



**安装**

```shell
#相关依赖库安装
yum install ‐y gcc
yum install libtermcap‐devel ncurses‐devel libevent‐devel readline‐devel

#获取包并解压
curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz
tar xzvf lua-5.3.0.tar.gz 

#安装
cd lua-5.3.0
make linux test
make install

#测试
lua
```



**执行**

可以使用文件执行：

```shell
vim hello.lua
#内容
print("hello world")

#执行
lua hello.lua
```



也可以直接`lua`命令进入控制台写



**注释**

```lua
--这是单行注释
--[[
这是多行注释
--]]
```



**关键字**

|          |       |       |        |
| -------- | ----- | ----- | ------ |
| and      | break | do    | else   |
| elseif   | end   | false | for    |
| function | if    | in    | local  |
| nil      | not   | or    | repeat |
| return   | then  | true  | until  |
| while    | goto  |       |        |



**变量**

```lua
--全局变量
a=1
--局部变量
local a=1
--变量没有赋值为 nil ，同样删除变量只需要赋值为 nil
a=nil
```



**数据类型**

 Lua 是动态类型语言，不用类型定义。 

| 数据类型 | 描述                                                         |
| :------- | :----------------------------------------------------------- |
| nil      | 无效值（在条件表达式中相当于false，做比较如x == "nil" 需要加双引号）。 |
| boolean  | 包含两个值：false和true。                                    |
| number   | 表示双精度类型的实浮点数                                     |
| string   | 字符串由一对双引号或单引号来表示                             |
| function | 由 C 或 Lua 编写的函数                                       |
| userdata | 表示任意存储在变量中的C数据结构                              |
| thread   | 表示执行的独立线路，用于执行协同程序                         |
| table    | Lua 中的表（table）其实是一个"关联数组"（associative arrays），数组的索引可以是数字、字符串或表类型。在 Lua 里，table 的创建是通过"构造表达式"来完成，最简单构造表达式是{}，用来创建一个空表。 |



测试：

```lua
print(type("Hello world"))      --> string
print(type(10.4*3))             --> number
print(type(print))              --> function
print(type(type))               --> function
print(type(true))               --> boolean
print(type(nil))                --> nil
print(type(type(X)))            --> string
```



**流程控制**

```lua
--if语句
if(布尔表达式)
then
   --[ 在布尔表达式为 true 时执行的语句 --]
end

--if else
if(布尔表达式)
then
   --[ 布尔表达式为 true 时执行该语句块 --]
else
   --[ 布尔表达式为 false 时执行该语句块 --]
end

--if嵌套
if( 布尔表达式 1)
then
   --[ 布尔表达式 1 为 true 时执行该语句块 --]
   if(布尔表达式 2)
   then
      --[ 布尔表达式 2 为 true 时执行该语句块 --]
   end
end
```



**循环**

同样的可以使用`goto`和`break`

```lua
--while循环
while(condition)
do
   statements
end

--for循环
--[[
var 从 exp1 变化到 exp2，每次变化以 exp3 为步长递增 var，并执行一次 "执行体"。exp3 是可选的，如果不指定，默认为1。
--]]
for var=exp1,exp2,exp3 do  
    <执行体>  
end  

--特殊的有，可以遍历输出 ipairs是Lua提供的一个迭代器函数，用来迭代数组。
#!/usr/local/bin/lua  
days = {"Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"}  
for i,v in ipairs(days) do  print(v) end  

--repeat until
repeat
   statements
until( condition )
```





嵌lua套循环：

```lua
for init,max/min value, increment
do
   for init,max/min value, increment
   do
      statements
   end
   statements
end

while(condition)
do
   while(condition)
   do
      statements
   end
   statements
end

repeat
   statements
   repeat
      statements
   until( condition )
until( condition )
```



**函数**

```lua
optional_function_scope function function_name( argument1, argument2, argument3..., argumentn)
    function_body
    return result_params_comma_separated
end

-- optional_function_scope:			全局 或者 局部（使用local）
-- result_params_comma_separated: 	函数返回值可以使用逗号隔开
```



例子：

```lua
function maximum (a)
    local mi = 1             -- 最大值索引
    local m = a[mi]          -- 最大值
    for i,val in ipairs(a) do
       if val > m then
           mi = i
           m = val
       end
    end
    return m, mi
end

print(maximum({8,10,23,12,5}))
```



可以使用`...`表示可变长参数

使用` select('#',...)`获取参数长度

使用` select(n,...)`获取第n个参数

```lua
do  
    function foo(...)  
        for i = 1, select('#', ...) do  -->获取参数总数
            local arg = select(i, ...); -->读取参数
            print("arg", arg);  --还可以紧密拼接 print("arg"..arg)
        end  
    end  
 
    foo(1, 2, 3, 4);  
end
--[[
输出：
arg    1
arg    2
arg    3
arg    4
--]]
```



**表**

```lua
-- 初始化表
mytable = {}

-- 指定值
mytable[1]= "Lua"

-- 移除引用 垃圾回收会释放内存
mytable = nil
```



**模块**

定义模块：

```lua
-- 文件名为 module.lua
-- 定义一个名为 module 的模块
module = {}
 
-- 定义一个常量
module.constant = "这是一个常量"
 
-- 定义一个函数
function module.func1()
    io.write("这是一个公有函数！\n")
end

local function func2()
    print("这是一个私有函数！")
end
 
function module.func3()
    func2()
end
 
return module
```



加载使用：

```lua
--[[
require("<模块名>")
或者
require "<模块名>"
--]]
--直接使用
require("module")
print(module.constant)
module.func3()

--定义别名使用
m = require("module")
print(m.constant)
m.func3()
```



### 4.3 OpenResty

基于nginx的可伸缩Web平台，外部人员可以通过lua脚本调用nginx内置模块。

https://github.com/openresty



#### 4.3.1 安装OpenResty

linux安装OpenResty：

```shell
#添加仓库执行命令
yum install yum-utils
yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo

#执行安装，会安装在默认的路径下/usr/local/openresty
yum -y install openresty
```



#### 4.3.2 Nginx

##### 4.3.2.1 安装

安装了openresty后默认会在目录下安装nginx，下面是复制的以前的笔记做备忘。

```shell
#编译工具与库文件
yum -y install make zlib zlib-devel gcc-c++ libtool  openssl openssl-devel

#安装PCRE可以让nginx支持Rewrite功能
cd /usr/local/src/
#建议本地下，太卡了
wget https://netix.dl.sourceforge.net/project/pcre/pcre/8.40/pcre-8.40.tar.gz
tar zxvf pcre-8.40.tar.gz
cd pcre-8.40
./configure
make && make install
#查看pcre版本
pcre-config --version

#安装nginx
cd /usr/local/src/
wget http://nginx.org/download/nginx-1.6.2.tar.gz
tar zxvf nginx-1.6.2.tar.gz
cd nginx-1.6.2
./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.40
make
make install
#查看版本
/usr/local/webserver/nginx/sbin/nginx -v

#nginx环境变量设置
vim /etc/profile
#内容
export PATH=$PATH:/usr/local/webserver/nginx/sbin/
#生效
source /etc/profile
nginx -v
```



##### 4.3.2.2 基础命令

```shell
#重载
nginx -s reload

#停止
nginx -s stop

#指定配置文件
nginx -c /usr/local/webserver/nginx/conf/nginx.conf
```

启动后可以直接访问ip:80



##### 4.3.2.3 启动OpenResty

```shell
/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf
```

<img src="./images/openresty界面.png" style="zoom:67%;" />





### 4.4 测试：数据更新到缓存实现

我们设定用户的请求为：`update_ad?categoryId=xxx`



#### 4.4.1 lua脚本

把数据从mysql查询出来保存到缓存中：

`vim /root/lua-5.3.0/zscript/update_ad.lua`



```lua
ngx.header.content_type="application/json;charset=utf8"
local cjson = require("cjson")
local mysql = require("resty.mysql")

local uri_args = ngx.req.get_uri_args()
local categoryId = uri_args["categoryId"]

local db = mysql:new()
db:set_timeout(1000)
local props = {
	host = "192.168.190.200",
	port = 3306,
	database = "shop_ad",
	user = "root",
	password = "123456"
}

local res = db:connect(props)
local select_sql = "SELECT AD_TITLE, AD_URL, AD_PIC_URL FROM SHOP_AD_CONTENT WHERE AD_STATUS = '1' AND AD_CATEGORY_ID= '"..categoryId.."' "
res = db:query(select_sql)
db:close()

local redis = require("resty.redis")
local red = redis:new()
red:set_timeout(2000)
local ip ="192.168.190.200"
local port = 6379
red:connect(ip,port)
red:auth("123456")
red:set("ad_"..categoryId,cjson.encode(res))
red:close()

ngx.say("{flag:true}")
```



#### 4.4.2 nginx配置

server下面添加：

```nginx
server{
	listen 80;
    server_name localhost;
    
    #把用于请求update_ad?categoryId=xxx交给脚本处理
    #脚本地址：/root/lua-5.3.0/zscript/update_ad.lua
    location /update_ad {
        content_by_lua_file /root/lua-5.3.0/zscript/update_ad.lua;
    }
}
```



完成之后重启nginx：

```shell
/usr/local/openresty/nginx/sbin/nginx -s reload
```



#### 4.4.3 脚本访问权限

如果直接访问会返回404，之后查看nginx日志：

```shell
tail -f /usr/local/openresty/nginx/logs/error.log
cannot open /root/lua-5.3.0/zscript/update_ad.lua: Permission denied, 
```



需要在nginx的配置文件上加上用户配置：

```shell
vim /usr/local/openresty/nginx/conf/nginx.conf

#user  nobody;
user root root;
```



完成之后重启nginx：

```shell
/usr/local/openresty/nginx/sbin/nginx -s reload
```



测试：

http://192.168.190.200/update_ad?categoryId=3



### 4.5 读取缓存数据

完整的路径应该是首选获取nginx缓存，如果缓存不存在获取redis缓存，不存在获取mysql数据。

我们设定用户的请求为：`read_ad?categoryId=xxx`

#### 4.5.1 lua脚本

`vim /root/lua-5.3.0/zscript/read_ad.lua`



这里的`ngx.shared.dis_cache`是定义的nginx缓存模块

```lua
ngx.header.content_type="application/json;charset=utf8"
local uri_args = ngx.req.get_uri_args()
local categoryId = uri_args["categoryId"]

local cache_ngx = ngx.shared.dis_cache;
local contentCache = cache_ngx:get('ad_cache_'..categoryId);
ngx.say('nginx',contentCache)

if contentCache == "" or contentCache == nil then
    local redis = require("resty.redis")
    local red = redis:new()
    red:set_timeout(2000)
    red:connect("192.168.190.200",6379)
    red:auth("123456")
    --单位ms
    red:set_timeout(2*60*1000)
    local rescontent = red:get("ad_"..categoryId)
    ngx.say('redis',rescontent)
    
    if ngx.null == rescontent then
        local cjson = require("cjson")
		local mysql = require("resty.mysql")
		local db = mysql:new()
		db:set_timeout(1000)
        local props = {
            host = "192.168.190.200",
            port = 3306,
            database = "shop_ad",
            user = "root",
            password = "123456"
        }
		local res = db:connect(props)
        local select_sql = "SELECT AD_TITLE, AD_URL, AD_PIC_URL FROM SHOP_AD_CONTENT WHERE AD_STATUS = '1' AND AD_CATEGORY_ID= '"..categoryId.."' "
		res = db:query(select_sql)
        local resJson = cjson.encode(res)
        red:set("ad_"..categoryId,resJson)
        ngx.say('mysql',resJson)
		db:close()
    else
        -- nginx缓存1分钟
        cache_ngx:set('ad_cache_'..categoryId, rescontent, 1*60)
        ngx.say(rescontent)
    end
    red:close()
else
    ngx.say(contentCache)
end
```



#### 4.5.2 nginx配置

`vim /usr/local/openresty/nginx/conf/nginx.conf`



我们需要添加缓存模块和路由信息：

```nginx
user root root;
worker_processes  1;

events {
    worker_connections  1024;
}


http {
    include       mime.types;
    default_type  application/octet-stream;

    #cache:定义缓存模块，大小为128M
    lua_shared_dict dis_cache 128m;

    sendfile        on;
    keepalive_timeout  65;

    server {
        listen       80;
        server_name  localhost;

        location / {
            root   html;
            index  index.html index.htm;
        }

        location /read_ad {
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```



重启：`/usr/local/openresty/nginx/sbin/nginx -s reload`





### 4.6 nginx限流

实现方式：

- 控制速率
- 控制并发连接数



#### 4.6.1 控制速率



##### 4.6.1.1 拒绝超出响应的请求

`vim /usr/local/openresty/nginx/conf/nginx.conf`



```nginx
http{
    ......
    
    #限流设置 binary_remote_addr根据请求地址进行限流
    #contentRateLimit 缓存空间名称，大小为10M
    #rate=2r/s 每秒两个请求
    limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s;
    
    server{
         location /read_ad {
            #使用限流配置
            limit_req zone=contentRateLimit;
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
    }
}
```

>binary_remote_addr 是一种key，表示基于 remote_addr(客户端IP) 来做限流，binary_ 的目的是压缩内存占用量。
>
>zone：定义共享内存区来存储访问信息， myRateLimit:10m 表示一个大小为10M，名字为myRateLimit的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。
>
>rate 用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求.我们这里设置成2 方便测试。



重启测试：`./nginx -s reload`

<img src="./images/nginx限流错误-浏览器.png" style="zoom:67%;" />

访问错误日志：

`2020/08/28 01:05:48 [error] 1642#1642: *31 limiting requests, excess: 0.300 by zone "contentRateLimit", client: x.x.x.x, server: localhost, request: "GET /read_ad?categoryId=1 HTTP/1.1", host: "192.168.190.200"`



##### 4.6.1.2 处理突发流量

在上面的例子`rate=2r/s`，也就是500ms只能处理一个请求，但是如果我们希望处理突发流量，把多余的请求先放入队列等待。

我们可以在`limit_req`后面加入`burst`字段，如下：

`limit_req zone=contentRateLimit burst=20;`

如果同时进入21个请求，那么多余的20个请求将会进入队列等待。当然如果超出21个请求，多余的会被拒绝。



当然，如果一直排队也会出现等待时间过长，比如这里的500ms处理一个请求，那么队列中最后一个请求要等待到10s之后了，我们可以加入`nodelay`参数：

```nginx
http{
    ......
    
    #限流设置 binary_remote_addr根据请求地址进行限流
    #contentRateLimit 缓存空间名称，大小为10M
    #rate=2r/s 每秒两个请求
    limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s;
    
    server{
         location /read_ad {
            #使用限流配置
            limit_req zone=contentRateLimit burst=5 nodelay;
            content_by_lua_file /root/lua-5.3.0/zscript/read_ad.lua;
        }
    }
}
```

此时如果同时有6个请求到达，那么队列中还有位置，nginx就会立即转发（想防御这6个事并行处理的），超出缓冲队列的请求会直接拒绝。



#### 4.6.2 控制并发量

`ngx_http_limit_conn_module`提供了并发量控制的能力，主要是利用`limit_conn_zone`和`limit_conn`两个指令，利用连接数限制某一个用户的**IP连接数量**来控制流量。



注意：只有服务器正在处理请求并且已经读取了整个请求头的时候，才会计算为有效连接。



##### 4.6.2.1 单个IP并发限制

编写本地测试接口：

端口8001，ip：192.168.190.1

```java
@RestController
public class TestController {
    @GetMapping("sleep")
    public String sleep() {
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return "sleep";
    }
}
```





配置nginx到本地测试：

```nginx
http{
	......
    #根据IP地址来限制，存储内存大小为10M addr是命名
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    
    server{
        ......
        #转发到本地测试接口
        location /sleep {
            #配置addr，表示每秒可以有两个请求
            limit_conn addr 2;
            proxy_pass http://192.168.190.1:8001/sleep;
        }
    }
}
```



使用JMeter测试可以看出来，每s第三个请求直接失败。



##### 4.6.2.2 固定接口并发限制

我们之前是通过对统一IP地址进行访问并发的限制，同时，我们可以对所有的请求也进行并发限制。

采用之前的接口来做测试，增加nginx的配置：

```nginx
http{
	......
    #根据IP地址来限制，存储内存大小为10M addr是命名
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    #对固定接口限制总的并发量
    limit_conn_zone $server_name zone=curserver:10m;
    
    server{
        ......
        #转发到本地测试接口
        location /sleep {
            #配置addr，表示每秒可以有两个请求
            limit_conn addr 2;
            #配置curserver，表示每s这个接口总共可以接收10个请求
            limit_conn curserver 10;
            proxy_pass http://192.168.190.1:8001/sleep;
        }
    }
}
```

也就是说，每秒sleep接口可以访问10次，但是来源于同一IP的请求只能有2个。



### 4.7 Canal同步数据

只要是有关缓存的问题就会涉及到数据的更新，不管我们是定时更新缓存数据还是在变化的时候马上写缓存，都存在一定的问题（更新不及时或者消耗接口时间）。同样的，在这个例子里面，我们希望有一个服务能够监听数据的更改，实时刷新缓存。



使用之前，我们需要在mysql里面开启日志



#### 4.7.1 工作原理

有关canal的介绍可以看官方的文档：https://github.com/alibaba/canal

<img src="./images/mysql主备复制原理.jpg" style="zoom: 80%;" />

上图展示了mysql的主从复制原理：

- MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看)
- MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)
- MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据



canal 工作原理

- canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
- MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
- canal 解析 binary log 对象(原始为 byte 流)



<img src="./images/Canal原理.png" style="zoom: 60%;" />

canal获取到数据之后，可以把数据刷新到Redis缓存中，在其他地方，也可以把数据写入ES、MySQL等处理。



#### 4.7.2 mysql开启binlog模式和创建同步账号

**开启binlog模式**

 我们这里是用docker安装的mysql，所以里面基本的环境都没有，可以使用` apt-get update`和`apt-get install vim`来安装vim

```shell
#进入mysql容器
docker exec -it z-mysql /bin/bash

#连接
mysql -h localhost -uroot -p123456

#查看mysql是否开启binlog模式，也就是log_bin的值如果ON则是开启
SHOW VARIABLES LIKE '%log_bin%';

#修改配置文件
vim /etc/mysql/mysql.conf.d/mysqld.cnf

[mysqld]
......

#binlog setting,第一个log-bin是二进制存储目录，第二个是当前数据库的唯一编号
log-bin=/var/lib/mysql/mysql-bin #开启 binlog
binlog-format=ROW #选择 ROW 模式
server-id=12345 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复

#修改完成之后，重启mysql服务或者直接docker restart z-mysql
/etc/init.d/mysql restart
```



**创建同步账号**

使用root账号创建用户并授权：

```shell
#进入mysql容器
docker exec -it z-mysql /bin/bash

#进入mysql
mysql -h localhost -uroot -p123456

#创建账号用于同步数据
#创建账号，账号名密码canal，'%'表示可以从任意主机登录
create user 'canal'@'%' IDENTIFIED by 'canal';
#授权：*.*表示所有数据库所有表
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT, SUPER ON *.* TO 'canal'@'%';
#权限生效
FLUSH PRIVILEGES;
```



#### 4.7.3 Canal容器安装

```powershell
#下载镜像
docker pull canal/canal-server

#创建容器
docker run -p 11111:11111 --name z-canal -d canal/canal-server 

#设置自启动
docker update --restart=always z-canal

#进入容器
docker exec -it z-canal /bin/bash

pwd
/home/admin
yum -y install vim

------------------------------------------------
#修改canal自身配置
vim canal-server/conf/canal.properties

#这里的id和mysql里面的server-id都表示服务的id，不能和mysql的server-id重复
canal.id = 1

------------------------------------------------
#同步配置
vim canal-server/conf/example/instance.properties

# 指定需要同步的数据库地址
# position info
canal.instance.master.address=192.168.190.200:3306

canal.instance.dbUsername=canal
canal.instance.dbPassword=canal

#数据库表的正则匹配，这里表示所有数据库(.*)所有表(.*)，中间(\\.)转义.
# table regex
canal.instance.filter.regex=.*\\..*


#配置完成后重启
docker restart z-canal
#也可以直接在容器里面重启
canal-server/bin/stop.sh
canal-server/bin/startup.sh
```



#### 4.7.4 查看日志

- 查看server日志：`tail -f canal-server/logs/canal/canal.log`
- 查看instance日志：`tail -f canal-server/logs/example/example.log`



#### 4.7.5 搭建canal微服务



##### 4.7.5.1 基础配置

pom依赖：使用github上面的依赖https://github.com/chenqian56131/spring-boot-starter-canal.git

```xml
        <dependency>
            <groupId>com.xpand</groupId>
            <artifactId>starter-canal</artifactId>
            <version>0.0.1-SNAPSHOT</version>
        </dependency>
```



配置文件：`application.yml`

```yaml
server:
  port: 8002
spring:
  application:
    name: canal-service
eureka:
  client:
    service-url:
      defaultZone: http://test:123456@127.0.0.1:8000/eureka/
  instance:
    prefer-ip-address: true
feign:
  hystrix:
    enabled: true
#canal配置
canal:
  client:
    instances:
      example:
        host: 192.168.190.200
        port: 11111
```





启动类：

```java
@SpringBootApplication
@EnableCanalClient
@EnableEurekaClient
public class CanalApplication {
    public static void main(String[] args) {
        SpringApplication.run(CanalApplication.class);
    }
}
```



##### 4.7.5.1 监听类

```java
package com.zr.canal.demo;

import com.alibaba.fastjson.JSONObject;
import com.alibaba.otter.canal.protocol.CanalEntry;
import com.xpand.starter.canal.annotation.*;
import lombok.extern.slf4j.Slf4j;

import java.util.List;

/**
 * Description:
 * 测试Canal 数据监听
 *
 * @author zhangr
 * 2020/8/31 16:56
 */
@CanalEventListener
@Slf4j
public class TestListener {
    //增加监听，需要看操作之后的数据
    @InsertListenPoint
    public void onEventInsert(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getAfterColumnsList())
            log.info("增加操作：{} : {}", column.getName(), column.getValue());
    }

    //更新监听，需要看操作之后的数据
    @UpdateListenPoint
    public void onEventUpdate(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getBeforeColumnsList())
            log.info("更新操作 修改前：{} : {}", column.getName(), column.getValue());

        for (CanalEntry.Column column : rowData.getAfterColumnsList())
            log.info("更新操作 修改后：{} : {}", column.getName(), column.getValue());
    }

    //删除监听，需要看操作之前的数据
    @DeleteListenPoint
    public void onEventDelete(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getBeforeColumnsList())
            log.info("删除操作：{} : {}", column.getName(), column.getValue());
    }

    //自定义监控：指定监听的类型、数据库、表、实例地址
    @ListenPoint(
            eventType = {CanalEntry.EventType.DELETE, CanalEntry.EventType.INSERT},
            schema = {"shop_ad"},
            table = {"SHOP_AD_CONTENT"},
            destination = "example"
    )
    public void onEventCustomize(CanalEntry.EventType eventType, CanalEntry.RowData rowData) {
        for (CanalEntry.Column column : rowData.getBeforeColumnsList())
            log.info("自定义操作 修改前：{} : {}", column.getName(), column.getValue());

        for (CanalEntry.Column column : rowData.getAfterColumnsList())
            log.info("自定义操作 修改后：{} : {}", column.getName(), column.getValue());
    }

}
```





## 5 商品搜索（ES）

这里因为资源的问题（docker下载太慢）还是按照网上教程的5.6.8的版本，对于新的版本（7）来说type已经被舍弃，也就是说实际上我们把index当做表维度而不是type，之前的数据如果需要迁移升级需要创建index。



### 5.1 docker安装ElasticSearch

es占用内存挺大的，可以先使用`free -h`看一下是否需要扩容：

```shell
#docker镜像下载
docker pull elasticsearch:5.6.8

#创建容器，其中9200是es与外部的通信端口，9300则是集群通信端口
docker run -id --name=z-es -p 9200:9200 -p 9300:9300 elasticsearch:5.6.8

#设置开机自启
docker update --restart=always z-es
```



测试访问：http://192.168.190.200:9200

```json
{
  "name" : "gWEiSMM",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "pPA-UIujQf661oDHIIKAzQ",
  "version" : {
    "number" : "5.6.8",
    "build_hash" : "688ecce",
    "build_date" : "2018-02-16T16:46:30.010Z",
    "build_snapshot" : false,
    "lucene_version" : "6.6.1"
  },
  "tagline" : "You Know, for Search"
}
```



ES从5版本以后默认不开启远程连接，客户端程序直接连接会报错。

我们需要修改ES配置开启远程连接：

```shell
#进入容器
docker exec -it z-es /bin/bash

#修改配置文件，没有vim使用apt-get update 和 apt-get install vim
vim /usr/share/elasticsearch/config/elasticsearch.yml

#去掉这一行的注释
transport.host: 0.0.0.0
#添加集群名称
cluster.name: my-application
#开启跨域
http.cors.enabled: true
#允许的域
http.cors.allow-origin: "*"
network.host: 192.168.190.200

#重启docker
docker restart z-es
```



此时可能会重启报错，因为我们放开了更多的配置，导致需要打开更多的文件和内存空间，因此我们需要修改一些系统调优的配置：

```shell
vim /etc/security/limits.conf

#追加配置，nofile单个进程允许打开的最大文件数
#soft nofile软限制
#hard nofile硬限制
* soft nofile 65536
* soft nofile 65536

-------------------------------

vim /etc/sysctl.conf

#追加配置，限制一个进程可以拥有的VMA（虚拟内存区域）数量
vm.max_map_count=655360

#执行下面命令 修改内核参数立即生效
sysctl -p

#重启虚拟机，即可访问
reboot
```





如果内存吃紧，可以把里面的jvm内存配置减小：

```shell
docker exec -it z-es /bin/bash

vim /etc/elasticsearch/jvm.options
-Xms1g
-Xmx1g
```



### 5.2 IK分词器安装

下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases

```shell
#下载后上传到服务器解压
unzip elasticsearch-analysis-ik-5.6.8.zip

#解压后修改文件名为ik
mv elasticsearch ik

#将文件复制到容器里面
docker cp ./ik z-es:/usr/share/elasticsearch/plugins

#重启容器
docker restart z-es
```



测试：

http://192.168.190.200:9200/_analyze?analyzer=ik_smart&pretty=true&text=狮子吃羚羊

显示结果：

```json
{
  "tokens" : [
    {
      "token" : "狮子",
      "start_offset" : 0,
      "end_offset" : 2,
      "type" : "CN_WORD",
      "position" : 0
    },
    {
      "token" : "吃",
      "start_offset" : 2,
      "end_offset" : 3,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "羚羊",
      "start_offset" : 3,
      "end_offset" : 5,
      "type" : "CN_WORD",
      "position" : 2
    }
  ]
}
```





自定义分词器：

在我们刚刚操作的ik文件里面修改配置文件

` vim /usr/share/elasticsearch/plugins/ik/config/IKAnalyzer.cfg.xml`

可以添加自定义分词文件，也可以停用词汇文件。



### 5.3 docker安装kibana

为了数据可视化，使用kibana数据分析统计工具。



```shell
#拉镜像
docker pull kibana:5.6.8

#创建容器 -e配置环境变量
docker run -itd -e ELASTICSEARCH_URL=http://192.168.190.200:9200 --name z-kibana --restart=always -p 5601:5601 kibana:5.6.8
```



测试地址：192.168.190.200:5601



进去之后可以看到要求配置索引：

![](./images/kibana初始界面.png)

 

这里后面在es里面创建索引之后就可以配置了。



### 5.4 DSL

下面这些操作都是在Kibana Dev Tools里面进行的，也可以直接使用curl操作。

具体语法如下：

```sh
curl -X<VERB> '<PROTOCOL>://<HOST>:<PORT>/<PATH>?<QUERY_STRING>' -d '<BODY>'

如：curl -X PUT “http://192.168.190.200:9200/adinfo/_mapping” -H 'Content-Type:application.json' -d '
{
	......
}
'
```



#### 5.4.1 索引

```sh
#查询全部索引
GET _cat/indices?v
GET _all

#创建索引，索引名必须小写
PUT /skuinfo

#查看指定索引
GET /skuinfo
GET /skuinfo,adinfo

#删除
DELETE /skuinfo

#关闭
POST /adinfo/_close

#打开
POST /adinfo/_open
```



#### 5.4.2 映射

```shell
#创建，这里的top就是type这个字段，现在新的版本被舍弃了
PUT adinfo/_mapping/top
{
 "properties":{
   "cat":{
     "type": "text",
     "analyzer": "ik_smart",
     "search_analyzer": "ik_smart"
   },
   "title":{
     "type": "text",
     "analyzer": "ik_smart",
     "search_analyzer": "ik_smart"
   },
   "sort_no":{
     "type": "long"
   }
 }  
}

#获取
GET adinfo/_mapping/top
```



#### 5.4.3 文档（数据）

新的版本会撤销这个type（实际变化不大），使用`_doc`代替所有的类型，所以也称为文档。

```sh
#添加数据，这里的1作为id，如果新版本没有type，写成PUT adinfo/_doc/1{}
#id相同的情况，删除原始数据再新增
PUT adinfo/top/1
{
  "cat": "类目1",
  "title": "电器广告1",
  "sort_no": "1"
}

#只能创建数据
#或者使用自动生成id，默认自动创建索引是开启的
POST adinfo/top
{
  "cat": "手机",
  "title": "小米手机",
  "sort_no": "100"
}

#查看
GET adinfo/top/1

#更新指定域
POST adinfo/top/1/_update
{
  "doc": {
    "cat": "类目2"
  } 
}

#删除
DELETE adinfo/top/1

#查看全部数据
GET adinfo/_search
GET adinfo/top/_search
```



#### 5.4.4 查询

```sh
#排序查询
GET adinfo/top/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "sort_no": {
        "order": "desc"
      }
    }
  ],
  "from": 0,
  "size": 2
}

#过滤查询
GET adinfo/top/_search
{
  "query": {
    "term": {
      "title": {
        "value": "华为"
      }
    }
  }
}

#多个term搜索
GET adinfo/top/_search
{
  "query": {
    "terms": {
      "title": [
        "华为",
        "小米"
      ]
    }
  }
}

#范围搜索
GET adinfo/top/_search
{
  "query": {
    "range": {
      "sort_no": {
        "gte": 1,
        "lte": 20
      }
    }
  }
}

#过滤搜索:存在某个域
GET adinfo/top/_search
{
  "query": {
    "exists": {
      "field": "cat" 
    }
  }
}

#组合查询
GET adinfo/top/_search
{
  "query": {
   "bool": {
     "must": [
       {
         "term": {
           "cat": {
             "value": "手机"
           }
         }
       },
       {
         "range": {
           "sort_no": {
             "gt": 100,
             "lte": 200
           }
         }
       }
     ]
   }
  }
}

#字符查询，这个根据分词器来查询
GET adinfo/top/_search
{
  "query": {
    "match": {
      "title": "旗舰"
    }
  }
}

#前缀查询
GET adinfo/top/_search
{
  "query": {
    "prefix": {
      "title": {
        "value": "华为"
      }
    }
  }
}

#多个域匹配
GET adinfo/top/_search
{
  "query": {
   "multi_match": {
     "query": "手机",
     "fields": [
       "cat",
       "title"
       ]
   }
  }
}
```



### 5.5 服务代码

